import pandas as pd

CSV_PATH = "resultat.csv"  # adapte si besoin

expected_cols = ["IPP", "DATE_NAISSANCE", "NDA", "UMA", "GHM", "DATE_ENTREE", "DATE_SORTIE"]

df = pd.read_csv(CSV_PATH, sep=";", skip_blank_lines=True, dtype=str, encoding="latin-1").dropna(how="all")
df.columns = [c.strip().upper() for c in df.columns]

# Comme ton code: si plus de colonnes, on renomme les 7 premières
if df.shape[1] >= len(expected_cols):
    df = df.iloc[:, :len(expected_cols)]
    df.columns = expected_cols

for c in ["IPP", "NDA", "UMA", "GHM"]:
    df[c] = df[c].fillna("").astype(str).str.strip()

df["DATE_ENTREE"] = pd.to_datetime(df["DATE_ENTREE"], dayfirst=True, errors="coerce")
df["DATE_SORTIE"] = pd.to_datetime(df["DATE_SORTIE"], dayfirst=True, errors="coerce")

df = df.dropna(subset=["DATE_ENTREE", "DATE_SORTIE", "UMA", "IPP"])
df = df.sort_values(["IPP", "DATE_ENTREE", "DATE_SORTIE"]).reset_index(drop=True)

# Comme ton code
df_base = df.drop_duplicates(subset=["IPP", "NDA", "UMA", "DATE_ENTREE", "DATE_SORTIE"], keep="first").copy()

def stay_key(ipp, nda, uma, de, ds):
    return (ipp, nda, uma, de, ds)

def pair_id(k1, k2):
    return tuple(sorted([k1, k2]))

# build map racine GHM par séjour (comme ton code)
stay_to_roots = {}
stay_to_root_full = {}
for _, r in df.iterrows():
    ipp, nda, uma, de, ds = r["IPP"], r["NDA"], r["UMA"], r["DATE_ENTREE"], r["DATE_SORTIE"]
    ghm = str(r["GHM"]).strip()
    k = stay_key(ipp, nda, uma, de, ds)
    if ghm and ghm.upper() not in ("NAN", "NONE") and len(ghm) >= 5:
        root = ghm[:5]
        stay_to_roots.setdefault(k, set()).add(root)
        stay_to_root_full.setdefault(k, {})
        stay_to_root_full[k].setdefault(root, ghm)

assigned = set()

# Étape 1: classer vrais doublons + "0 nuit" (comme ton code)
vrai_doublon = 0
doublon_0_nuit = 0

for ipp, group in df_base.groupby("IPP", sort=False):
    g = group.reset_index(drop=True)
    n = len(g)
    for i in range(n):
        nda1, uma1, de1, ds1 = g.loc[i, ["NDA", "UMA", "DATE_ENTREE", "DATE_SORTIE"]]
        k1 = stay_key(ipp, nda1, uma1, de1, ds1)

        j = i + 1
        while j < n:
            de2 = g.loc[j, "DATE_ENTREE"]
            if pd.isna(de2):
                j += 1
                continue
            if de2 > ds1 and de2 != ds1:
                break

            nda2, uma2, ds2 = g.loc[j, ["NDA", "UMA", "DATE_SORTIE"]]
            k2 = stay_key(ipp, nda2, uma2, de2, ds2)

            if nda1 == nda2:
                j += 1
                continue

            pid = pair_id(k1, k2)
            if pid in assigned:
                j += 1
                continue

            if (uma1 == uma2) and (de1 == de2) and (ds1 == ds2):
                vrai_doublon += 1
                assigned.add(pid)
            elif (uma1 != uma2) and (de1 == de2) and (ds1 == ds2):
                doublon_0_nuit += 1
                assigned.add(pid)

            j += 1

# Étape 2: contigus stricts + UMA différente + même root GHM (comme ton code)
contig_candidats_stricts = 0
contig_avec_root = 0
examples = []

for ipp, group in df_base.groupby("IPP", sort=False):
    g = group.reset_index(drop=True)
    n = len(g)
    for i in range(n):
        nda1, uma1, de1, ds1 = g.loc[i, ["NDA", "UMA", "DATE_ENTREE", "DATE_SORTIE"]]
        k1 = stay_key(ipp, nda1, uma1, de1, ds1)

        j = i + 1
        while j < n:
            de2 = g.loc[j, "DATE_ENTREE"]
            if pd.isna(de2):
                j += 1
                continue
            if de2 > ds1 and de2 != ds1:
                break

            nda2, uma2, ds2 = g.loc[j, ["NDA", "UMA", "DATE_SORTIE"]]
            k2 = stay_key(ipp, nda2, uma2, de2, ds2)

            if nda1 == nda2:
                j += 1
                continue

            pid = pair_id(k1, k2)
            if pid in assigned:
                j += 1
                continue

            is_contig = (ds1 == de2) or (ds2 == de1)
            if not is_contig or uma1 == uma2:
                j += 1
                continue

            contig_candidats_stricts += 1

            roots1 = stay_to_roots.get(k1, set())
            roots2 = stay_to_roots.get(k2, set())
            common = roots1.intersection(roots2)

            if common:
                contig_avec_root += 1
                assigned.add(pid)

                if len(examples) < 10:
                    root = sorted(list(common))[0]
                    ghm1 = stay_to_root_full.get(k1, {}).get(root, "")
                    ghm2 = stay_to_root_full.get(k2, {}).get(root, "")
                    examples.append({
                        "IPP": ipp,
                        "NDA1": nda1, "UMA1": uma1, "DE1": de1, "DS1": ds1, "GHM1": ghm1,
                        "NDA2": nda2, "UMA2": uma2, "DE2": de2, "DS2": ds2, "GHM2": ghm2,
                        "ROOT": root
                    })

            j += 1

print("=== Résumé ===")
print("VRAI_DOUBLON:", vrai_doublon)
print("DOUBLON_0_NUIT:", doublon_0_nuit)
print("CONTIGUS stricts candidats (avant filtre root):", contig_candidats_stricts)
print("CONTIGUS stricts avec root commun:", contig_avec_root)

if examples:
    ex = pd.DataFrame(examples)
    print("\n=== Exemples CONTIGUS (10) ===")
    # affichage compact
    cols = ["IPP","NDA1","UMA1","DE1","DS1","GHM1","NDA2","UMA2","DE2","DS2","GHM2","ROOT"]
    print(ex[cols].to_string(index=False))
else:
    print("\nAucun exemple contigu trouvé avec tes règles.")
