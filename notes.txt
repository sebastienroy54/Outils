import streamlit as st
import pandas as pd
import numpy as np
import subprocess
import time
import random
from pathlib import Path
from datetime import datetime
from openpyxl import load_workbook
from shutil import copyfile
import re
from openpyxl.styles import Border, Side, Alignment, Font
from collections import defaultdict

BASE_DIR = Path("C:/Users/4251352/Portail_outils")
DATA_DIR = BASE_DIR / "data"
SQL_DIR = BASE_DIR / "SQL"
PATRON_TIM_XLSX = DATA_DIR / "tableau_rum_tim.xlsx"   # source pour construire le dictionnaire TIM
PATRON_FILL_XLSX = DATA_DIR / "Tableau.xlsx"          # patron √† copier et remplir

TNS_MAP = {
    "CCH": "SIP1CCH.WORLD",
    "BRC": "SIP1BRC.WORLD",
    "HTD": "SIP_HTD.WORLD"
}

def safe_show_exception(e):
    st.session_state.last_exception_str = str(e)
    st.error("Une erreur est survenue. V√©rifiez vos fichiers ou contactez le support.")
    if "show_exception" not in st.session_state:
        st.session_state.show_exception = False
    st.session_state.show_exception = st.checkbox("Afficher d√©tails techniques", value=st.session_state.show_exception)
    if st.session_state.show_exception and "last_exception_str" in st.session_state:
        st.code(st.session_state.last_exception_str)

def run_sqlplus_and_wait(cmd, timeout=30):
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    start = time.time()
    output = ""
    while True:
        if proc.poll() is not None:
            out, _ = proc.communicate()
            output += (out or "")
            break
        if time.time() - start > timeout:
            proc.kill()
            raise TimeoutError("Timeout lors de l'ex√©cution sqlplus.")
        time.sleep(0.1)
    return output

def build_sql_spool_rum(site_label, file_spool_path, mode, month, year):
    if mode == "mois":
        start = f"01/{int(month):02d}/{year}"
        end_expr = f"LAST_DAY(TO_DATE('01/{int(month):02d}/{year}','DD/MM/YYYY'))"
        where_clause = (f"D8EEUE BETWEEN TO_DATE('{start}','DD/MM/YYYY') AND {end_expr}")
    else:
        start = f"01/01/{year}"
        end_expr = f"LAST_DAY(TO_DATE('01/{int(month):02d}/{year}','DD/MM/YYYY'))"
        where_clause = (f"D8SOUE >= TO_DATE('{start}','DD/MM/YYYY') AND D8EEUE <= {end_expr}")
    sql = f"""
SET HEADING OFF
SET FEEDBACK OFF
SET PAGESIZE 0
SET LINESIZE 2000
SET TRIMSPOOL ON
spool {file_spool_path}
SELECT CDURM_P || ';' || COUNT(*)
FROM EPI
WHERE {where_clause}
GROUP BY CDURM_P;
spool off
exit;
"""
    return sql

def read_spool_csv_to_df(spool_path):
    p = Path(spool_path)
    if not p.exists():
        return pd.DataFrame(columns=["UMA", "COUNT"])
    try:
        df = pd.read_csv(p, sep=';', header=None, dtype=str, names=["UMA", "COUNT"], engine="python")
        df["UMA"] = df["UMA"].astype(str).str.strip()
        df["COUNT"] = pd.to_numeric(df["COUNT"].astype(str).str.strip().replace("", "0"), errors="coerce").fillna(0).astype(int)
        return df
    except Exception:
        lines = p.read_text(encoding="utf-8", errors="ignore").splitlines()
        rows = []
        for line in lines:
            if ";" in line:
                a, b = line.split(";", 1)
                rows.append({"UMA": a.strip(), "COUNT": int(b.strip() or 0)})
        return pd.DataFrame(rows)

# --- Parsing UMA/TIM from patron: now includes libelle and type ---
def extract_uma_code_by_space(uma):
    if not isinstance(uma, str):
        return ""
    s = uma.strip()
    return s.split(" ", 1)[0].strip() if s else ""

def split_tims(cell):
    if not isinstance(cell, str):
        return []
    cell = cell.strip()
    if cell.lower() in {"nan", "none", ""}:
        return []
    parts = re.split(r'[/;,|]+', cell)
    return [p.strip() for p in parts if p.strip()]

def normalize_dmu(raw):
    if not isinstance(raw, str):
        return ""
    s = raw.strip()
    return s.split(" ", 1)[0].strip() if s else ""

def build_tim_uma_dict(patron_path):
    """
    Retourne dictionnaire enrichi :
    TIM -> site -> DMU -> [ {code, libelle, type} , ... ]
    """
    df = pd.read_excel(patron_path, engine="openpyxl", dtype=str)
    df.columns = [c.strip() for c in df.columns]

    for col in ["Site", "UMA", "DMU"]:
        if col not in df.columns:
            raise KeyError(f"Colonne manquante : {col}")

    tim_ref_col = "TIM R√©f√©rent" if "TIM R√©f√©rent" in df.columns else None
    relance_col = "Relance" if "Relance" in df.columns else None
    type_col = "Type" if "Type" in df.columns else None

    def clean_tim(tim):
        if not isinstance(tim, str):
            return ""
        s = tim.replace("\u200b", "") \
               .replace("\ufeff", "") \
               .replace("\u00a0", " ") \
               .replace("\u200e", "") \
               .replace("\u200f", "")
        s = re.sub(r'\s+', ' ', s).strip()
        return s

    result = {}
    for _, row in df.iterrows():
        raw_uma_full = row.get("UMA", "")
        if not isinstance(raw_uma_full, str) or raw_uma_full.strip() == "" or raw_uma_full.startswith("Total DMU"):
            continue
        uma_code = extract_uma_code_by_space(raw_uma_full)
        uma_libelle = raw_uma_full.strip()
        site = str(row.get("Site", "")).strip() or "UNKNOWN"
        raw_dmu = row.get("DMU", "")
        dmu_code = normalize_dmu(raw_dmu)
        if dmu_code == "":
            continue

        uma_type_raw = row.get(type_col, "") if type_col else ""
        uma_type = (str(uma_type_raw).strip().upper() if isinstance(uma_type_raw, str) else "")
        if uma_type not in {"HC", "HDJ"}:
            # fallback : si pas de type, pr√©sumer HC (ou tu peux forcer √† HDJ selon r√®gles)
            uma_type = "HC"

        tims = []
        if tim_ref_col:
            tims += split_tims(row.get(tim_ref_col, ""))
        if relance_col:
            tims += split_tims(row.get(relance_col, ""))

        if not tims:
            continue

        uma_obj = {"code": uma_code, "libelle": uma_libelle, "type": uma_type}
        for tim in tims:
            tim_norm = clean_tim(tim)
            if not tim_norm:
                continue
            result.setdefault(tim_norm, {}).setdefault(site, {}).setdefault(dmu_code, []).append(uma_obj)

    # Ensure UMA lists are unique per DMU (by code) and sorted
    def uniq_sort_umas(list_of_umas):
        seen = {}
        for uma in list_of_umas:
            seen.setdefault(uma["code"], uma)  # keep first occ for libelle/type
        out = list(seen.values())
        out.sort(key=lambda x: x["code"])
        return out

    result_listified = {
        tim: {
            site: {dmu: uniq_sort_umas(umas) for dmu, umas in dmus.items()}
            for site, dmus in sites.items()
        }
        for tim, sites in result.items()
    }
    return result_listified

def merge_vertical_conditionnel(ws, col_idx, df_col, start_row, group_col=None):
    """
    Fusion verticale des cellules identiques dans une colonne.
    Si group_col est fourni, fusion seulement si la valeur du groupe est identique.
    """
    if len(df_col) == 0:
        return
    current_val = df_col.iloc[0]
    current_group = group_col.iloc[0] if group_col is not None else None
    start_idx = 0
    for i in range(1, len(df_col)):
        val = df_col.iloc[i]
        group_val = group_col.iloc[i] if group_col is not None else None
        same = (val == current_val) and (group_col is None or group_val == current_group)
        if not same:
            if i - 1 > start_idx:
                ws.merge_cells(start_row=start_row + start_idx, start_column=col_idx,
                               end_row=start_row + i - 1, end_column=col_idx)
            start_idx = i
            current_val = val
            current_group = group_val
    # fusion de la derni√®re s√©rie
    if len(df_col) - 1 > start_idx:
        ws.merge_cells(start_row=start_row + start_idx, start_column=col_idx,
                       end_row=start_row + len(df_col) - 1, end_column=col_idx)

def draw_border_lines_for_tim_blocks(ws, start_row, df_sorted, first_col, last_col, site_col_idx=None):
    """
    Trace des bordures horizontales : 
    - haut et bas pour chaque TIM
    - ligne suppl√©mentaire entre sites si site_col_idx fourni
    """
    thin = Side(border_style="thin", color="000000")
    top_border = Border(top=thin)
    bottom_border = Border(bottom=thin)

    # Bordures TIM
    tim_groups = df_sorted.groupby("TIM").apply(lambda x: (x.index.min(), x.index.max()))
    for tim, (start_idx, end_idx) in tim_groups.items():
        top_row = start_row + start_idx
        bottom_row = start_row + end_idx
        for c in range(first_col, last_col + 1):
            ws.cell(row=top_row, column=c).border = Border(
                left=ws.cell(row=top_row, column=c).border.left,
                right=ws.cell(row=top_row, column=c).border.right,
                top=thin,
                bottom=ws.cell(row=top_row, column=c).border.bottom
            )
            ws.cell(row=bottom_row, column=c).border = Border(
                left=ws.cell(row=bottom_row, column=c).border.left,
                right=ws.cell(row=bottom_row, column=c).border.right,
                top=ws.cell(row=bottom_row, column=c).border.top,
                bottom=thin
            )

    # Bordures entre sites
    if site_col_idx is not None:
        for i in range(1, len(df_sorted)):
            if df_sorted["SITE"].iloc[i] != df_sorted["SITE"].iloc[i - 1]:
                row = start_row + i
                for c in range(first_col, last_col + 1):
                    ws.cell(row=row, column=c).border = Border(
                        left=ws.cell(row=row, column=c).border.left,
                        right=ws.cell(row=row, column=c).border.right,
                        top=thin,
                        bottom=ws.cell(row=row, column=c).border.bottom
                    )

def apply_uma_exceptions(df):
    """
    Applique les exceptions UMA sans inventer de colonnes.
    - Transfert UMA '150' HTD -> TIM Cliniciens
    - Transfert 040X CCH : cod√©s -> relanc√©s
    - Transfert 561C, 591C, 591J CCH : cod√©s par TIM HDJ
    """
    # --- 150 HTD -> TIM Cliniciens ---
    mask_150 = df["UMA HC"].str.startswith("150") & (df["SITE"] == "HTD")
    mask_cliniciens = df["TIM"] == "Cliniciens"

    if mask_150.any() and mask_cliniciens.any():
        # somme des RUM cod√©s pour 150 HTD
        val_codes_mois = df.loc[mask_150, "RUM cod√©s mois"].sum()
        val_codes_cum = df.loc[mask_150, "RUM cod√©s cumul√©s"].sum()
        # appliquer √† toutes les lignes TIM Cliniciens
        df.loc[mask_cliniciens, "RUM cod√©s mois"] = val_codes_mois
        df.loc[mask_cliniciens, "RUM cod√©s cumul√©s"] = val_codes_cum
        # laisser 150 HTD vide apr√®s transfert
        df.loc[mask_150, ["RUM cod√©s mois", "RUM cod√©s cumul√©s"]] = np.nan

    # --- 040X CCH : transf√©rer cod√©s -> relanc√©s ---
    mask_040X = df["UMA HC"].str.startswith("040X") & (df["SITE"] == "CCH")
    if mask_040X.any():
        df.loc[mask_040X, "RUM relanc√©s mois"] = df.loc[mask_040X, "RUM cod√©s mois"]
        df.loc[mask_040X, "RUM relanc√©s cumul√©s"] = df.loc[mask_040X, "RUM cod√©s cumul√©s"]
        # vider les cod√©s
        df.loc[mask_040X, ["RUM cod√©s mois", "RUM cod√©s cumul√©s"]] = np.nan

    # --- 561C, 591C, 591J CCH : cod√©s par TIM (HDJ) ---
    for code in ["561C", "591C", "591J"]:
        mask = df["UMA HDJ"].str.startswith(code) & (df["SITE"] == "CCH")
        if mask.any():
            df.loc[mask, "RUM cod√©s mois"] = df.loc[mask, "RUM relanc√©s mois"]
            df.loc[mask, "RUM cod√©s cumul√©s"] = df.loc[mask, "RUM relanc√©s cumul√©s"]
            df.loc[mask, ["RUM relanc√©s mois", "RUM relanc√©s cumul√©s"]] = np.nan

    return df

# --- √âcriture Excel ---
def write_copy_with_values_to_patron(df, patron_path):
    from io import BytesIO
    wb = load_workbook(filename=str(patron_path))
    ws = wb.active

    # Header detection
    header_row = None
    for r in range(1, 30):
        values = [(ws.cell(row=r, column=c).value or "").strip().lower() for c in range(1, ws.max_column+1)]
        if "tim" in values and "site" in values:
            header_row = r
            break
    if not header_row:
        header_row = 1

    name_to_col = {str(ws.cell(row=header_row, column=c).value).strip(): c for c in range(1, ws.max_column+1)}

    col_map = {
        "TIM": name_to_col.get("TIM"),
        "SITE": name_to_col.get("SITE"),
        "UMA HC": name_to_col.get("UMA HC"),
        "RUM_codes_mois": name_to_col.get("RUM cod√©s mois"),
        "RUM_codes_cumul√©s": name_to_col.get("RUM cod√©s cumul√©s"),
        "UMA HDJ": name_to_col.get("UMA HDJ"),
        "DMU": name_to_col.get("DMU"),
        "RUM_rel_mois": name_to_col.get("RUM relanc√©s mois"),
        "RUM_rel_cum": name_to_col.get("RUM relanc√©s cumul√©s")
    }

    start = header_row + 1
    df_sorted = df.sort_values(by=["TIM", "SITE", "DMU", "UMA HC", "UMA HDJ"]).reset_index(drop=True)

    # Fill cells
    for idx, row in df_sorted.iterrows():
        excel_row = start + idx
        ws.cell(row=excel_row, column=col_map["TIM"]).value = row["TIM"]
        ws.cell(row=excel_row, column=col_map["SITE"]).value = row["SITE"]
        ws.cell(row=excel_row, column=col_map["DMU"]).value = row["DMU"]

        if row["UMA HC"]:
            ws.cell(row=excel_row, column=col_map["UMA HC"]).value = row["UMA HC"]
            ws.cell(row=excel_row, column=col_map["RUM_codes_mois"]).value = int(row["RUM cod√©s mois"]) if pd.notna(row["RUM cod√©s mois"]) else None
            ws.cell(row=excel_row, column=col_map["RUM_codes_cumul√©s"]).value = int(row["RUM cod√©s cumul√©s"]) if pd.notna(row["RUM cod√©s cumul√©s"]) else None
        if row["UMA HDJ"]:
            ws.cell(row=excel_row, column=col_map["UMA HDJ"]).value = row["UMA HDJ"]
            ws.cell(row=excel_row, column=col_map["RUM_rel_mois"]).value = int(row["RUM relanc√©s mois"]) if pd.notna(row["RUM relanc√©s mois"]) else None
            ws.cell(row=excel_row, column=col_map["RUM_rel_cum"]).value = int(row["RUM relanc√©s cumul√©s"]) if pd.notna(row["RUM relanc√©s cumul√©s"]) else None

    # Fusion et bordures horizontales
    merge_vertical_conditionnel(ws, col_map["TIM"], df_sorted["TIM"], start)
    merge_vertical_conditionnel(ws, col_map["SITE"], df_sorted["SITE"], start, group_col=df_sorted["TIM"])
    merge_vertical_conditionnel(ws, col_map["DMU"], df_sorted["DMU"], start, group_col=df_sorted["TIM"])
    draw_border_lines_for_tim_blocks(ws, start, df_sorted, 1, ws.max_column, site_col_idx=col_map["SITE"])

    # Bordures verticales pour toutes les colonnes
    thin = Side(border_style="thin", color="000000")
    for r in range(1, ws.max_row+1):
        for c in range(1, ws.max_column+1):
            cell = ws.cell(row=r, column=c)
            cell.border = Border(left=thin, right=thin, top=cell.border.top, bottom=cell.border.bottom)

    # Centrage uniquement TIM, SITE, DMU
    for idx, row in df_sorted.iterrows():
        excel_row = start + idx
        for c in [col_map["TIM"], col_map["SITE"], col_map["DMU"]]:
            ws.cell(row=excel_row, column=c).alignment = Alignment(horizontal="center", vertical="center")

    output = BytesIO()
    wb.save(output)
    output.seek(0)
    return output

def page_rum():
    st.title("Remplissage RUM ‚Äî TIM")
    if "oracle_connected" not in st.session_state or not st.session_state.oracle_connected:
        st.error("Vous devez d'abord vous connecter sur la page Connexion.")
        return

    mois = st.selectbox("Choisir le mois", list(range(1, 13)), index=datetime.now().month - 1)
    annees = list(range(2013, datetime.now().year + 1))
    annee = st.selectbox("Choisir l'ann√©e", annees, index=len(annees)-1)
    bouton = st.button("Lancer le traitement RUM")
    st.markdown("**Remarque :** le script va interroger les 3 bases (CCH, BRC, HTD) et g√©n√©rer un tableau par TIM.")
    if not bouton:
        return

    try:
        progress = st.progress(0)
        progress.progress(5)

        st.write("üîπ Construction du dictionnaire TIM/UMA...")
        tim_dict = build_tim_uma_dict(PATRON_TIM_XLSX)
        st.write(f"‚úÖ TIM dict construit, {len(tim_dict)} TIM trouv√©s.")

        UMA_WEIGHTS = {
            ("130", "Clara HEBRARD"): 1/3,
            ("130", "Maria Louisa ESTEVES"): 2/3
        }

        st.write("üîπ Construction du DataFrame df_patron...")
        # --- DataFrame patron construction ---
        rows = []
        for tim, sites in tim_dict.items():
            for site, dmus in sites.items():
                for dmu, umas in dmus.items():
                    for uma in umas:
                        rows.append({
                            "TIM": tim,
                            "SITE": site,
                            "UMA HC": uma["libelle"] if uma["type"] == "HC" else "",
                            "RUM cod√©s mois": 0.0 if uma["type"] == "HC" else np.nan,
                            "RUM cod√©s cumul√©s": 0.0 if uma["type"] == "HC" else np.nan,
                            "UMA HDJ": uma["libelle"] if uma["type"] == "HDJ" else "",
                            "DMU": dmu,
                            "RUM relanc√©s mois": 0.0 if uma["type"] == "HDJ" else np.nan,
                            "RUM relanc√©s cumul√©s": 0.0 if uma["type"] == "HDJ" else np.nan,
                        })
        df_patron = pd.DataFrame(rows)
        st.write(f"‚úÖ df_patron cr√©√© : {df_patron.shape[0]} lignes")
        progress.progress(30)

        st.write("üîπ Extraction des codes UMA pour correspondance...")
        df_patron["UMA_HC_code"] = df_patron["UMA HC"].apply(extract_uma_code_by_space)
        df_patron["UMA_HDJ_code"] = df_patron["UMA HDJ"].apply(extract_uma_code_by_space)

        st.write("üîπ Comptage du nombre de TIM par UMA_code...")
        uma_to_tim_count = defaultdict(int)
        for tim, sites in tim_dict.items():
            for site, dmus in sites.items():
                for dmu, umas in dmus.items():
                    for uma in umas:
                        uma_to_tim_count[uma["code"]] += 1
        st.write(f"‚úÖ UMA counts: {len(uma_to_tim_count)} codes UMA")

        # Ex√©cution SQL (par site)
        for idx_site, (site_label, tns) in enumerate(TNS_MAP.items()):
            st.write(f"üîπ Traitement site {site_label} ({idx_site+1}/{len(TNS_MAP)})")
            spool_mois = DATA_DIR / f"RUM_MOIS_{site_label}.csv"
            spool_cum = DATA_DIR / f"RUM_CUMULE_{site_label}.csv"
            sql_mois = build_sql_spool_rum(site_label, str(spool_mois), "mois", mois, annee)
            sql_cum = build_sql_spool_rum(site_label, str(spool_cum), "cumule", mois, annee)
            tmp_sql_mois = SQL_DIR / f"rum_mois_{site_label}.sql"
            tmp_sql_cum = SQL_DIR / f"rum_cumule_{site_label}.sql"
            tmp_sql_mois.write_text(sql_mois, encoding="utf-8")
            tmp_sql_cum.write_text(sql_cum, encoding="utf-8")

            st.write("üì° Lancement sqlplus mois...")
            out_m = run_sqlplus_and_wait(f"sqlplus -S {st.session_state.oracle_user}/{st.session_state.oracle_password}@{tns} @{tmp_sql_mois}", timeout=60)
            st.write("üì° Lancement sqlplus cumul√©...")
            out_c = run_sqlplus_and_wait(f"sqlplus -S {st.session_state.oracle_user}/{st.session_state.oracle_password}@{tns} @{tmp_sql_cum}", timeout=60)

            df_m = read_spool_csv_to_df(spool_mois)
            df_c = read_spool_csv_to_df(spool_cum)
            st.write(f"üìä Spool df_m : {df_m.shape[0]} lignes, df_c : {df_c.shape[0]} lignes")

            # Calcul RUM
            st.write("üîπ Calcul RUM par UMA...")
            for tim, sites in tim_dict.items():
                for site, dmus in sites.items():
                    for dmu, umas in dmus.items():
                        for uma in umas:
                            uma_code = uma["code"]
                            uma_type = uma["type"]
                            base_m = df_m.loc[df_m["UMA"] == uma_code, "COUNT"].sum()
                            base_c = df_c.loc[df_c["UMA"] == uma_code, "COUNT"].sum()
                            default_count = uma_to_tim_count.get(uma_code, 1)
                            weight = UMA_WEIGHTS.get((uma_code, tim), 1.0 / default_count if default_count > 0 else 1.0)
                            assigned_m = base_m * weight
                            assigned_c = base_c * weight

                            if uma_type == "HC":
                                mask = (
                                    (df_patron["TIM"] == tim) &
                                    (df_patron["SITE"] == site) &
                                    (df_patron["DMU"] == dmu) &
                                    (df_patron["UMA_HC_code"] == uma_code)
                                )
                                df_patron.loc[mask, "RUM cod√©s mois"] = assigned_m
                                df_patron.loc[mask, "RUM cod√©s cumul√©s"] = assigned_c
                            else:  # HDJ
                                mask = (
                                    (df_patron["TIM"] == tim) &
                                    (df_patron["SITE"] == site) &
                                    (df_patron["DMU"] == dmu) &
                                    (df_patron["UMA_HDJ_code"] == uma_code)
                                )
                                df_patron.loc[mask, "RUM relanc√©s mois"] = assigned_m
                                df_patron.loc[mask, "RUM relanc√©s cumul√©s"] = assigned_c

            try:
                tmp_sql_mois.unlink()
                tmp_sql_cum.unlink()
            except:
                st.warning(f"‚ö† Impossible de supprimer {tmp_sql_mois} ou {tmp_sql_cum}")

            progress.progress(30 + idx_site * 20)

        st.write("üîπ Application des exceptions UMA...")
        df_patron = apply_uma_exceptions(df_patron)

        # --- suppression colonnes temporaires ---
        df_patron.drop(columns=["UMA_HC_code", "UMA_HDJ_code"], inplace=True)

        st.write("üîπ √âcriture dans le patron Excel en m√©moire...")
        output = write_copy_with_values_to_patron(df_patron, PATRON_FILL_XLSX)
        st.write("‚úÖ Fichier pr√™t en m√©moire")
        progress.progress(100)

        st.success(f"Traitement termin√© ‚Äî fichier pr√™t au t√©l√©chargement")
        st.download_button(
            "T√©l√©charger le fichier rempli",
            data=output,
            file_name=f"tableau_rum_tim_rempli_{mois:02d}_{annee}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        st.write("‚ùå Exception captur√©e ! :", e)
        safe_show_exception(e)

# ----------------- Page Connexion + session + main (inchang√©s) -----------------
def page_connexion():
    st.title("Connexion Oracle")
    if not st.session_state.logged_in:
        with st.form("connexion"):
            st.subheader("Connexion Oracle")
            user = st.text_input("üë§ Nom d'utilisateur Oracle :", key="conn_user")
            password = st.text_input("üîë Mot de passe :", type="password", key="conn_pwd")
            submitted = st.form_submit_button("üöÄ Se connecter")

        if submitted:
            if not user or not password:
                st.error("Veuillez renseigner vos identifiants Oracle.")
                return
            try:
                st.info("Test de connexion...")
                tns_alias = TNS_MAP["CCH"]
                test_sql_path = SQL_DIR / "test_connexion.sql"
                test_sql_path.write_text("select 1 from dual;\nexit;", encoding="utf-8")
                cmd = f"sqlplus -S {user}/{password}@{tns_alias} @{test_sql_path}"
                out = run_sqlplus_and_wait(cmd, timeout=3)
                if "1" in out:
                    st.session_state.oracle_connected = True
                    st.session_state.logged_in = True
                    st.session_state.oracle_user = user
                    st.session_state.oracle_password = password
                    st.session_state.page = "rum"
                    st.rerun()
                else:
                    st.error("Connexion √©chou√©e. V√©rifiez vos identifiants Oracle.")
            except Exception as e:
                safe_show_exception(e)
            finally:
                try:
                    test_sql_path.unlink()
                except:
                    pass
    else:
        st.success("Connexion active.")
        if st.button("‚û° Aller √† la page RUM"):
            st.session_state.page = "rum"
            st.rerun()

def ensure_session_vars():
    defaults = {
        "logged_in": False,
        "oracle_connected": False,
        "page": "connexion",
        "oracle_user": "",
        "oracle_password": "",
        "last_exception_str": "",
        "show_exception": False
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

def main():
    st.set_page_config(page_title="RUM TIM", layout="centered")
    ensure_session_vars()
    if st.session_state.page == "connexion":
        page_connexion()
    elif st.session_state.page == "rum":
        if not st.session_state.logged_in:
            st.session_state.page = "connexion"
            st.rerun()
        page_rum()
    else:
        st.session_state.page = "connexion"
        st.rerun()

if __name__ == "__main__":
    main()
