import pandas as pd
import numpy as np
from pathlib import Path
import re
from openpyxl.utils import get_column_letter

# ============================================================
# PARAMÈTRES CHEMINS
# ============================================================
BASE_DIR = Path(r"C:\Users\4251352\Documents\DMI")

PATH_ORBIS = BASE_DIR / "Liste des DMI codés.csv"
PATH_SEDI  = BASE_DIR / "Extraction DMI SEDITRACE 2025 CCH.xlsx"

OUT_FILE = BASE_DIR / "DMI_SEDITRACE_NON_CODES_ORBIS.xlsx"

# ============================================================
# HELPERS
# ============================================================
def read_csv_auto(path: Path) -> pd.DataFrame:
    encodings = ["utf-8", "cp1252", "latin1"]
    seps = [None, ";", ",", "\t", "|"]
    last_err = None
    for enc in encodings:
        for sep in seps:
            try:
                if sep is None:
                    return pd.read_csv(path, sep=None, engine="python", encoding=enc, dtype=str)
                return pd.read_csv(path, sep=sep, engine="python", encoding=enc, dtype=str)
            except Exception as e:
                last_err = e
    raise RuntimeError(f"Impossible de lire {path}. Dernière erreur: {last_err}")

def ensure_cols(df: pd.DataFrame, required: list, label: str):
    missing = [c for c in required if c not in df.columns]
    if missing:
        raise KeyError(f"{label}: colonnes manquantes: {missing}")

def clean_id_like(x: pd.Series) -> pd.Series:
    s = x.astype("string").str.strip()
    s = s.replace({"": pd.NA, "nan": pd.NA, "NaN": pd.NA, "None": pd.NA})
    s = s.str.replace(r"^(\d+)\.0$", r"\1", regex=True)

    def sci_to_int(val):
        if val is pd.NA or val is None:
            return pd.NA
        v = str(val).strip()
        if re.match(r"^[+-]?\d+(\.\d+)?[eE][+-]?\d+$", v):
            try:
                f = float(v)
                if np.isfinite(f) and abs(f - round(f)) < 1e-9:
                    return str(int(round(f)))
                return str(f).rstrip("0").rstrip(".")
            except Exception:
                return v
        return v

    return s.map(sci_to_int).astype("string").str.strip()

def norm_ref(x: pd.Series) -> pd.Series:
    return (
        x.astype("string")
         .str.strip()
         .str.replace(r"\s+", " ", regex=True)
         .str.upper()
    )

def to_num(s: pd.Series) -> pd.Series:
    x = s.astype("string").str.strip().str.replace(",", ".", regex=False)
    return pd.to_numeric(x, errors="coerce")

# --- Conversion dates robuste (formats explicites)
def parse_date_fr_day(series: pd.Series) -> pd.Series:
    """
    Retourne une date (jour) robuste depuis des strings type:
    - dd/mm/yyyy
    - dd/mm/yyyy hh:mm:ss
    - dd/mm/yyyy hh:mm
    - dd-mm-yyyy ...
    """
    s = series.astype("string").str.strip()

    # Tentatives explicites (FR)
    dt = pd.to_datetime(s, format="%d/%m/%Y %H:%M:%S", errors="coerce")
    dt2 = pd.to_datetime(s, format="%d/%m/%Y %H:%M", errors="coerce")
    dt3 = pd.to_datetime(s, format="%d/%m/%Y", errors="coerce")
    dt4 = pd.to_datetime(s, format="%d-%m-%Y %H:%M:%S", errors="coerce")
    dt5 = pd.to_datetime(s, format="%d-%m-%Y", errors="coerce")

    # Fallback "générique" FR
    fallback = pd.to_datetime(s, errors="coerce", dayfirst=True)

    out = dt.fillna(dt2).fillna(dt3).fillna(dt4).fillna(dt5).fillna(fallback)
    return out.dt.normalize()

def parse_datetime_fr(series: pd.Series) -> pd.Series:
    """Datetime (avec heure) robuste FR, fallback dayfirst."""
    s = series.astype("string").str.strip()
    dt = pd.to_datetime(s, format="%d/%m/%Y %H:%M:%S", errors="coerce")
    dt2 = pd.to_datetime(s, format="%d/%m/%Y %H:%M", errors="coerce")
    dt3 = pd.to_datetime(s, format="%d/%m/%Y", errors="coerce")
    fallback = pd.to_datetime(s, errors="coerce", dayfirst=True)
    return dt.fillna(dt2).fillna(dt3).fillna(fallback)

def make_key(nip: pd.Series, date_pose_dt: pd.Series, ref: pd.Series) -> pd.Series:
    nip_n = clean_id_like(nip)
    ref_n = norm_ref(ref)
    # Si date_pose_dt est NaT -> KEY sera NA
    return nip_n + "|" + date_pose_dt.dt.strftime("%Y-%m-%d") + "|" + ref_n

# --- Excel formatting
def autosize_worksheet_columns(ws, min_width=10, max_width=60):
    for col_idx, col_cells in enumerate(ws.columns, start=1):
        max_len = 0
        for cell in col_cells:
            if cell.value is None:
                continue
            max_len = max(max_len, len(str(cell.value)))
        width = max(min_width, min(max_width, max_len + 2))
        ws.column_dimensions[get_column_letter(col_idx)].width = width

def set_excel_date_format(ws, header_row=1, formats=None):
    if not formats:
        return
    header_map = {}
    for cell in ws[header_row]:
        header_map[str(cell.value)] = cell.column
    for col_name, fmt in formats.items():
        if col_name not in header_map:
            continue
        col_idx = header_map[col_name]
        for r in range(header_row + 1, ws.max_row + 1):
            ws.cell(row=r, column=col_idx).number_format = fmt

# ============================================================
# 1) ORBIS : set des clés codées (IPP + jour + ref)
# ============================================================
orbis = read_csv_auto(PATH_ORBIS)

ORBI_REQ = [
    "IPP du patient",
    "Date de l’intervention",
    "Référence commerciale du DMI",
]
ensure_cols(orbis, ORBI_REQ, "ORBIS")

orbis_date_dt = parse_date_fr_day(orbis["Date de l’intervention"])
orbis_key = make_key(
    nip=orbis["IPP du patient"],
    date_pose_dt=orbis_date_dt,
    ref=orbis["Référence commerciale du DMI"]
)

# On retire les clés où la date n'a pas été parsée (sinon ça fausse tout)
orbis_keys = set(orbis_key.dropna().unique())

# ============================================================
# 2) SEDITRACE : construire les lignes + filtrer "non codés ORBIS"
# ============================================================
sedi = pd.read_excel(PATH_SEDI, dtype=str)

SEDI_REQ = [
    "IPP",
    "Posé le",
    "Réference",
    "Nbre",
    "LPPR",
    "Libellé",
    "Fournisseur",
    "N° de Lot",
    "DATEHEURESAISIE",
    "Praticien",
    "PRIX_LPPR",
    "PxTot",
]
ensure_cols(sedi, SEDI_REQ, "SEDITRACE")

sedi_dt_pose = parse_date_fr_day(sedi["Posé le"])
sedi_dt_saisie = parse_datetime_fr(sedi["DATEHEURESAISIE"])

sedi_std = pd.DataFrame({
    "NIP": clean_id_like(sedi["IPP"]),
    "Date_pose_dt": sedi_dt_pose,
    "Date_saisie_dt": sedi_dt_saisie,
    "Ref_commerciale": sedi["Réference"],
    "Quantite": to_num(sedi["Nbre"]),
    "Code_LPP": clean_id_like(sedi["LPPR"]),
    "Libelle_DMI": sedi["Libellé"],
    "Fournisseur": sedi["Fournisseur"],
    "No_lot": sedi["N° de Lot"],
    "Medecin_poseur": sedi["Praticien"],
    "Prix_unitaire_LPPR": to_num(sedi["PRIX_LPPR"]),
    "Prix_total": to_num(sedi["PxTot"]),
})

sedi_std["KEY"] = make_key(sedi_std["NIP"], sedi_std["Date_pose_dt"], sedi_std["Ref_commerciale"])

# IMPORTANT : si Date_pose_dt est NaT, KEY devient <NA> ou contient "NaT" -> on exclut
sedi_std = sedi_std.dropna(subset=["Date_pose_dt", "NIP"])
sedi_std = sedi_std[sedi_std["Ref_commerciale"].notna()]

# non codés ORBIS
non_codes = sedi_std[~sedi_std["KEY"].isin(orbis_keys)].copy()
non_codes["No_serie"] = pd.NA  # volontairement vide

# ============================================================
# 3) DETAIL + FILTRE PxTot > 0
# ============================================================
detail = pd.DataFrame({
    "NIP": non_codes["NIP"],
    "Date de pose": non_codes["Date_pose_dt"],             # date Excel
    "Médecin poseur": non_codes["Medecin_poseur"],
    "Date saisie SEDITRACE": non_codes["Date_saisie_dt"],  # datetime Excel
    "Nom du laboratoire fournisseur": non_codes["Fournisseur"],
    "Réf commerciale": non_codes["Ref_commerciale"],
    "Numéro de lot": non_codes["No_lot"],
    "Numéro de série": non_codes["No_serie"],
    "Code LPP": non_codes["Code_LPP"],
    "Libellé DMI": non_codes["Libelle_DMI"],
    "Nbre": non_codes["Quantite"],
    "PRIX_LPPR": non_codes["Prix_unitaire_LPPR"],
    "PxTot": non_codes["Prix_total"],
    "Clé technique (IPP|date|ref)": non_codes["KEY"],
})

# supprimer TOUTES les lignes sans € (PxTot <= 0 ou vide)
detail["_PxTot_num"] = pd.to_numeric(detail["PxTot"], errors="coerce")
detail = detail[detail["_PxTot_num"] > 0].copy()
detail = detail.drop(columns=["_PxTot_num"])

# ============================================================
# 4) SYNTHESE par Libellé (sur detail filtré) + TOTAL
# ============================================================
tmp = detail.copy()
tmp["_nbre"] = pd.to_numeric(tmp["Nbre"], errors="coerce")
tmp["_pxtot"] = pd.to_numeric(tmp["PxTot"], errors="coerce")

synthese = (
    tmp
    .groupby("Libellé DMI", dropna=False)
    .agg(
        nb_lignes=("NIP", "size"),
        nb_patients=("NIP", pd.Series.nunique),
        nbre_total=("_nbre", "sum"),
        manque_a_gagner_estime=("_pxtot", "sum"),
    )
    .reset_index()
    .sort_values("manque_a_gagner_estime", ascending=False)
)

total_row = pd.DataFrame([{
    "Libellé DMI": "TOTAL",
    "nb_lignes": int(synthese["nb_lignes"].sum()),
    "nb_patients": int(tmp["NIP"].nunique()),
    "nbre_total": float(synthese["nbre_total"].sum()),
    "manque_a_gagner_estime": float(synthese["manque_a_gagner_estime"].sum()),
}])

synthese = pd.concat([synthese, total_row], ignore_index=True)

# ============================================================
# 5) Export Excel + autosize + format dates FR
# ============================================================
with pd.ExcelWriter(OUT_FILE, engine="openpyxl") as writer:
    detail.to_excel(writer, sheet_name="DETAIL_NON_CODES", index=False)
    synthese.to_excel(writer, sheet_name="SYNTHESE_LIBELLE", index=False)

    ws_detail = writer.book["DETAIL_NON_CODES"]
    ws_syn = writer.book["SYNTHESE_LIBELLE"]

    autosize_worksheet_columns(ws_detail)
    autosize_worksheet_columns(ws_syn)

    # Forcer format FR des dates dans Excel (affichage)
    set_excel_date_format(ws_detail, formats={
        "Date de pose": "DD/MM/YYYY",
        "Date saisie SEDITRACE": "DD/MM/YYYY HH:MM:SS",
    })

print("✅ OK")
print(f"Fichier généré : {OUT_FILE}")
