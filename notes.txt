### EXH JULIA ###
00 08 * * *  /home/crontab/julia_exh.sh >> /var/log/exh.log 2>1
#40 06 * * *  /home/crontab/julia_exhghu.sh >> /var/log/exh.log 2>1
#35 06 * * 1  /home/crontab/julia_exh_ssr.sh >> /var/log/exh.log 2>1
#30 08 * * *  /home/crontab/julia_exh-daily.sh >> /var/log/exh.log 2>1

### REJETS JULIA ###
#50 06 * * *  /home/crontab/julia_rejets_simpa.sh >> /var/log/exh.log 2>1

### MONORUM UHCD > 0j ### Execution le Lundi Matin
#00 08 * * 1 /home/crontab/julia_monorum_uhcd.sh

### EOH ISO ### Execution le premier jour du mois
#00 05 01 * * /home/crontab/julia_eoh.sh

### DBAI ### Execution le premier jour du mois (trimestriel)
#00 07 01 * * /home/crontab/julia_dbai.sh

### MONO UHCD (Python) ###
00 09 * * 1 /home/crontab/python_monouhcd.sh >> /var/log/python_monouhcd.log 2>&1

### DOUBLONS (Python) ###
00 10 * * 1 /home/crontab/python_doublons.sh >> /var/log/python_doublons.log 2>&1

julia_exh.sh :
#!/bin/sh
echo Lancement Cron
SHELL=/bin/sh PATH=/bin:/sbin:/usr/bin:/usr/sbin:/root/:/usr/bin/docker:/root/.juliaup/bin

cd /home/julia/exh/
#julia exh_daf.jl 
julia exh.jl 

code julia :
# Usage :
# > julia exh.jl [force] [recipients_group] [site] [remontee]
# - force : force l'envoie du mail (par défaut, le mail ne part que les lundi, jeudi, les lendemains de remontée et les 7 jours avant la remontée)
# - recipients_group : groupe de destinataire des mails, si non précisé envoi au destinataire par défaut
#   - dev / rouge / obscure  : ing
#   - bleue / bleu: mim + ing
#   - jv
# - site : trigramme du site à cibler parmi les sites possibles (ALL_SITES), à séparer par des espaces pour envoi multisite :
# 	ex: > julia exh.jl rouge force SLS lrb bjn cch # envoie du mail à sls lrb & bjn 
# - remontee : cible une remontée spécifique, 
# 	ex: > julia exh.jl force 2024M06

using DataFramesMeta, Dates, XLSX, HTTP, JSON, CSV, JSON3, PrettyTables, LoggingExtras, TimerOutputs

DS = include(normpath(@__DIR__,"../julia-pmsi/dimsum/dim_sum.jl"))
include(normpath(@__DIR__,"src/queries/queries.jl"))
include(normpath(@__DIR__,"src/utilities/mail.jl"))
include(normpath(@__DIR__,"src/utilities/html.jl"))

# ---- Setup

# Note: to enable debug level in REPL : > ENV["JULIA_DEBUG"] = Main
global_logger(TeeLogger(
    # ConsoleLogger(Logging.Debug),
	ConsoleLogger(Logging.Info),
    DatetimeRotatingFileLogger(normpath(@__DIR__,"logs"), raw"\l\o\g_YYYY-mm-dd.\l\o\g") do io, args
        println(io, "[",Dates.format(now(), dateformat"yyyy-mm-dd HH:MM:SS"), "][", uppercase(string(args.level)), "] ", args.message)
    end
))

const DATA_FOLDER = joinpath(@__DIR__, "data")
const INPUT_FOLDER = joinpath(@__DIR__, "data/in")
const OUTPUT_FOLDER = joinpath(@__DIR__, "data/out")

# const ALL_SITES = ["lrb","sls","rdb","bch","bjn","lmr","brt","vpd"]
const ALL_SITES = ["cch"]


# const DEV_MAIL = "julien.vigneron@aphp.fr";
const DEV_MAIL = "julien.vigneron@aphp.fr, dimitri.belard@aphp.fr";
# const DEV_MAIL = "julien.vigneron@aphp.fr, dimitri.belard@aphp.fr, noemie.leclerc-du-sablon@aphp.fr";
# const DEV_MAIL = "julien.vigneron@aphp.fr, dimitri.belard@aphp.fr, noemie.leclerc-du-sablon@aphp.fr, hassina.lefevre@aphp.fr";

const MAIL_RECIPIENTS_GROUP_DEV = 1
# const DEV_RECIPIENTS = Dict(
# 	"simpa_sls" => DEV_MAIL,
# 	"simpa_lrb" => DEV_MAIL,
# 	"simpa_bch" => DEV_MAIL,
# 	"simpa_bjn" => DEV_MAIL,
# 	"simpa_brt" => DEV_MAIL,
# 	"simpa_lmr" => DEV_MAIL,
# 	"simpa_rdb" => DEV_MAIL,
# 	"simpa_vpd" => DEV_MAIL
# )
const DEV_RECIPIENTS = Dict(
	"simpa_cch" => DEV_MAIL
)

const MAIL_RECIPIENTS_GROUP_ALL = 2
const DEFAULT_RECIPIENTS = Dict(
	"simpa_cch" => "samir.bouam@aphp.fr,sebastien.roy@aphp.fr,marion.leveque@aphp.fr,dimitri.belard@aphp.fr",
)

const MAIL_RECIPIENTS_GROUP_MIMING = 3
const MIMING_RECIPIENTS = Dict(
	"simpa_cch" => "samir.bouam@aphp.fr,sebastien.roy@aphp.fr,marion.leveque@aphp.fr,dimitri.belard@aphp.fr",
)


const RECIPIENTS_GROUPS = Dict(
	MAIL_RECIPIENTS_GROUP_DEV => DEV_RECIPIENTS,
	MAIL_RECIPIENTS_GROUP_ALL => DEFAULT_RECIPIENTS,
	MAIL_RECIPIENTS_GROUP_MIMING => MIMING_RECIPIENTS,
)

# const INFOMED_DSN = Dict(
# 	"sls" => "infomed_husll",
# 	"lrb" => "infomed_husll",
# 	"bch" => "infomed_hupnvs",
# 	"bjn" => "infomed_hupnvs",
# 	"brt" => "infomed_hupnvs",
# 	"lmr" => "infomed_hupnvs",
# 	"rdb" => "infomed_hurdb"
# )

const INFOMED_DSN = Dict(
	"cch" => "infomed_cch"
)

const INFOMED_DSN_V3 = "infomedv3_cch"

# Files
const FILE_CALENDRIER = "calendrier_remontees_mco.csv"
const FILE_LIBELLES_NESTOR = "erreurs_nestor.csv"
const FILE_PAQ = "paq.csv"
const TEMPLATE_PATH = joinpath(DATA_FOLDER,"template_exh_infomedv3_v2.xlsx")

# Column names
const COL_RESUMES_ATTENDUS = "Résumés attendus"
const COL_RESUMES_LIES = "Résumés liés"
const COL_RESUMES_MANQUANTS = "Résumés manquants"
const COL_TAUX_EXHAUSTIVITE = "Taux exhaustivité"
const COL_ERREUR_NESTOR = "Erreur"
const COL_NIVEAU_ERREUR_NESTOR = "Niveau"
const COL_QUANTITE = "Total"
const COL_NON_VU = "Non Vue"
const COL_EN_ATTENTE = "En Attente"
const COL_MODIFIE = "Vérifiée et Modifiée"
const COL_VALIDE = "Vérifiée et Non Modifiée"
const COL_QUANTITE_MASQUE = "Total Masquée"
const COL_NON_VU_MASQUE = "Non Vue Masquée"
const COL_EN_ATTENTE_MASQUE = "En Attente Masquée"
const COL_MODIFIE_MASQUE = "Vérifiée et Modifiée Masquée"
const COL_VALIDE_MASQUE = "Vérifiée et Non Modifiée Masquée"
const COL_SERVICE = "Service"
const COL_MODE_HOSPIT = "HP/HC"
const COL_TYPE_MARQUEUR = "Type"

# Date formats
const DATE_FORMAT = "yyyy-mm-dd"
const DATE_FORMAT_FILE = "yyyymmdd_HHMMSS"
const DATE_FORMAT_FR = "dd/mm/yyyy"

is_monday(date) = dayofweek(date) == 1
is_thursday(date) = dayofweek(date) == 4

# ---- Remontées

get_calendrier_remontee() = CSV.File(joinpath(DATA_FOLDER,FILE_CALENDRIER),dateformat=DATE_FORMAT; skipto=2)

function get_info_remontee(date_or_remontee)
	cal = get_calendrier_remontee()
	if date_or_remontee isa Date 
		return NamedTuple(cal[findfirst(r -> r[4] <= date_or_remontee && date_or_remontee <= r[5], cal)])
	elseif date_or_remontee isa String 
		t = match(r"(?<annee>\d{4})M(?<mois>\d{2})",date_or_remontee)
		if isnothing(t) 
			@info "can't parse remontee :'$date_or_remontee'"
			return
		end
		id_remontee = parse(Int64,t[:annee] * t[:mois])
		try
			return NamedTuple(cal[findfirst(r -> r[1] == id_remontee, cal)])
		catch
			@info "get_info_remontee: $date_or_remontee not found in calendar"
		end
	else 
		@info "get_info_remontee format not found $date_or_remontee"
	end
	return nothing
end

function get_info_remontee_lambda(date)
	current_remontee = get_info_remontee(date)
	cal = get_calendrier_remontee()
	year_diff = startswith(current_remontee.intitule,"M12") ? 2 : 1
	NamedTuple(cal[findfirst(r -> r[6] == "M12 " * string(year(date) - year_diff), cal)])
end

function is_day_after_remontee(date)
	cal = get_calendrier_remontee()
	findfirst(r -> r.remontee == date - Day(1), cal) !== nothing
end

function get_months(info_remontee,cumul)
	r = info_remontee.id;
	cumul == false && return [r]
	[Int(m) for m in range((floor(r/100) * 100) + 1, stop=r)];
end

# 202307 => "M1 - M6 2023"
function get_remontees_before(info_remontee)
	r = info_remontee.id
	"M1 - M$(mod(r,100)-1) $(Int(floor(r/100)))"
end

# ---- Structures

function get_structures_sirius(site)
	data = query_structures_sirius(site)
	data = @chain data begin
		@rtransform :date_fin = ismissing(:date_fin) ? Date(3000,1,1) : Date(:date_fin,dateformat"yyyy-mm-dd H:M:S")
		# ne prendre que les structures actives (date de fin == max == 3000)
		@subset :date_fin .== maximum(:date_fin)
		# ne prendre que les uh ouverte le plus récemment pour ne garder que le dernier nom de service
		@orderby sortperm(:date_deb, rev=true)
		@by [:uma,:uma_lib] $first
		unique(@select _ :uma :uma_lib :service_lib :mode_hospit)
		@orderby :uma
		@rename begin
			:UMA = :uma
			:UMA_LIB = :uma_lib
			:SERVICE = :service_lib
			:MODE_HOSPIT = :mode_hospit
		end
	end
	# fix pour UH 716 et 715 passées des UMA 527 et 528 vers 527J et 528J en 2023
	if site === "SLS"
		push!(data, ["527", "HDJ CRN ANES LOCAL", "CHIR GEN DIG EN","P"])
		push!(data, ["528", "HDJ CRN MEDIC", "CHIR GEN DIG EN","P"])
	end
	@pt data
	data
end

function get_structures(site,dsn,info_remontee)
	structures = leftjoin(query_structures_simpa(dsn, info_remontee),get_structures_sirius(site),on = :UMA)
	@select structures :SERVICE :UMA :UMA_LIB :UH :LIBELLE_UH :URMC :LIBELLE_URMC :CHPMSI :TYPE :DEBUT_VALIDITE :FIN_VALIDITE :MAJ :LIBELLE_UMA :MODE_HOSPIT
end

# ---- Exhaustivité

function get_exhaustivite(data,months,structures)
	data_tmp = transform(data[(in(months).(data.MOIS)),:], :NORES => ByRow(x -> coalesce(x,0)) => :NORES )
	data_total = combine(groupby(data_tmp[:,[:CODE_UMA,:NDA]],[:CODE_UMA]), nrow => :attendu)
	data_present = combine(groupby(data_tmp[(data_tmp.NORES .> 0),[:CODE_UMA,:NORES]],[:CODE_UMA]), nrow => :present)
	data_exh = @chain data_total begin
		leftjoin(data_present, on = [:CODE_UMA])
		@rtransform :present = coalesce(:present,0)
		@rtransform begin
			:manquant = :attendu - :present
			:pourcentage = round((:present / :attendu); digits=4)
		end
		leftjoin(unique(structures[Not(ismissing.(structures[:,:SERVICE])),[:MODE_HOSPIT,:UMA,:UMA_LIB,:SERVICE]]), on=[:CODE_UMA => :UMA])
		@rtransform :CODE_UMA = string(:CODE_UMA)
		@rtransform :UMA = string(:CODE_UMA," ",:UMA_LIB)
		sort!([:CODE_UMA])
	end
	
	@pt data_exh
	@select data_exh :SERVICE :MODE_HOSPIT :CODE_UMA :UMA :attendu :present :manquant :pourcentage
end

function get_exh_current_month(exh_raw_data,info_remontee,structures)
	df = get_exhaustivite(exh_raw_data,info_remontee.id,structures)
	count_attendu = sum(df.attendu)
	count_attendu_hp = sum(df[(df[:,:MODE_HOSPIT] .=== "P"), :attendu])
	count_attendu_hc = sum(df[(df[:,:MODE_HOSPIT] .=== "C"), :attendu])
	count_manquant = sum(df.manquant)
	count_manquant_hp = sum(df[(df[:,:MODE_HOSPIT] .=== "P"), :manquant])
	count_manquant_hc = sum(df[(df[:,:MODE_HOSPIT] .=== "C"), :manquant])
	percent_exh = round(((count_attendu - count_manquant) / count_attendu) * 100; digits=2)
	percent_exh = percent_exh - floor(percent_exh) > 0 ? percent_exh : Int(percent_exh)
	(
		count_attendu = count_attendu,
		count_manquant = count_manquant,
		percent_exh = percent_exh,
		count_attendu_hp = count_attendu_hp,
		count_attendu_hc = count_attendu_hc,
		count_manquant_hp = count_manquant_hp,
		count_manquant_hc = count_manquant_hc
	)
end

function get_exhaustivite_mensuelle(data,months,structures,column_name)
	remontees = []
	for month in months
		df = get_exhaustivite(data,[month],structures)
		rename!(df, Dict(Symbol(column_name) => string(month)))
		push!(remontees, df[:,[:CODE_UMA,:UMA,Symbol(string(month))]])
	end
	rem = remontees[1]
	for r in remontees[2:end]
		rem = outerjoin(rem,r,on=[:CODE_UMA,:UMA])
	end
	for c in names(rem)
		rem[:,Symbol(string(c))] .= coalesce.(rem[:,Symbol(string(c))],0)
	end
	uma_service = @chain structures begin
		@rsubset !ismissing(:SERVICE)
		@select :MODE_HOSPIT :UMA :SERVICE
		unique()
		@rtransform :UMA = string(:UMA)
	end
	@chain leftjoin(rem,uma_service,on=[:CODE_UMA => :UMA]) begin
		@select :SERVICE Not(:CODE_UMA)
		sort(_,[Symbol(last(names(_)))],rev=true)
		@select :SERVICE :MODE_HOSPIT All()	
	end	
end

function get_90z_current(cmd90_data, info_remontee)
	nrow(cmd90_data) === 0 && return DataFrame()
	current_year = Int(floor(info_remontee.id/100))
	current_month = mod(info_remontee.id,100)
	current_to_match = string(current_year,"-",lpad(string(current_month),2,'0'))
	cmd90_data[(occursin.(current_to_match,cmd90_data.DDS_RSS,)),:]
end

function get_RSS_non_groupes_current(rss_non_groupes_data, info_remontee)
	nrow(rss_non_groupes_data) === 0 && return DataFrame()
	current_year = Int(floor(info_remontee.id/100))
	current_month = mod(info_remontee.id,100)
	current_to_match = string(current_year,"-",lpad(string(current_month),2,'0'))
	rss_non_groupes_data[(occursin.(current_to_match,rss_non_groupes_data.DDS_RSS,)),:]
end

function get_RUM_manquants(epi_non_groupe_data,structures)
	nrow(epi_non_groupe_data) === 0 && return DataFrame()
	@chain epi_non_groupe_data begin
		# recuperer les rss partiellement codés (NAS avec au moins un epi avec nores)
		@aside nas_rss_partiellement_codé = @chain _ begin
			@rsubset !ismissing(:NORES)
			@by :NAS :notes = "Codage présent sur d'autres RUM du RSS [UMA = " * join(unique(:UMA),",") *"]"
		end
		@rsubset ismissing(:NORES)
		@rtransform begin
			:TYPE = :TYPE == "HC" ? :TYPE : "HDJ"
			:DDE_UH = :DDE_UH[1:16]
			:DDS_UH = :DDS_UH[1:16]
		end
		leftjoin(nas_rss_partiellement_codé,on=:NAS)
		# ajouter libelles UMA / UH
		@aside umas = @chain structures begin
			@rtransform :UMA_LIB = :UMA * " " * :UMA_LIB
			@select :UMA :UMA_LIB
			unique()
		end
		@aside uhs = @chain structures begin
			@rtransform :UH_LIB = :UH * " " * :LIBELLE_UH
			@select :UH :UH_LIB
			unique()
		end
		@rtransform :UMA = ismissing(:UMA) ? "" : :UMA
		leftjoin(umas,on=:UMA)
		leftjoin(uhs,on=:UH)
		@rename begin
			:DDE_RSS = :DDE
			:DDS_RSS = :DDS
			:DDE_RUM_UH = :DDE_UH
			:DDS_RUM_UH = :DDS_UH
		end
		@select :TYPE :NDA :NAS :DDE_RUM_UH :DDS_RUM_UH :UMA_LIB :UH_LIB :DDE_RSS :DDS_RSS :notes
		@orderby :DDS_RSS :NAS
	end
end

# ---- Nestor

function get_regles_paq()
	@chain CSV.File(joinpath(DATA_FOLDER,FILE_PAQ),dateformat=DATE_FORMAT; skipto=2, types=Dict(:site => String),delim=';') |> DataFrame begin
		@rtransform begin
			:regles_nestor = String.(split(:regles_nestor,","))
			:regles_nestor_n2 = ismissing(:regles_nestor_n2) ? [] : String.(split(:regles_nestor_n2,","))
		end
	end 
end

function get_regles_paq_level(paq=nothing)
	paq = isnothing(paq) ? get_regles_paq() : paq
	l1 = @chain paq begin
		@select :site :site_tri :regles_nestor
		flatten(:regles_nestor)
		@transform :level1 = 1
		@rename :code_erreur = :regles_nestor
	end

	l2 = @chain paq begin
		@select :site :site_tri :regles_nestor_n2
		flatten(:regles_nestor_n2)
		@transform :level2 = 1
		@rename :code_erreur = :regles_nestor_n2
	end

	level = @chain leftjoin(l1,l2,on=[:site,:site_tri,:code_erreur]) begin
		coalesce.(0)
		@rtransform :level = :level1 + :level2
	end
	level 
end

function get_libelles_nestor(site)
	@chain query_libelles_marqueurs(site) begin
		@rsubset :type == "Nestor"
		@rename :type_marqueur = :categorie
		@rtransform :type_marqueur = (:type_marqueur == "RUM AP-HP" ? "RUM" : (:type_marqueur == "RDS AP-HP" ? "RDS" : "Autre"))
		@select :code_erreur :type_marqueur :libelle 
	end
end

# erreur, nb_erreur
function get_nestor(site,data,regles_to_keep = nothing, regles_level = nothing)
	nrow(data) === 0 && return DataFrame()
	
	# add nestor erreur libelle + cleanup + sort
	nestor = @chain leftjoin(get_libelles_nestor(site), (@select data Not(:libelle)), on = :code_erreur) begin
		@rtransform begin
			:erreur = :code_erreur * " - " * :libelle
			:etat = ismissing(:etat) ? "" : :etat
		end
		coalesce.(0)
		sort(:nb_erreur,rev=true)
	end

	if(regles_to_keep !== nothing)
		@pt regles_to_keep
		nestor = nestor[[r in regles_to_keep for r in nestor.code_erreur],:]
	end

	# ajout niveau / priorité erreurs 
	if !isnothing(regles_level)
		regles_level_site = @rsubset regles_level :site_tri == site
		nestor = @chain leftjoin(nestor, (@select regles_level_site :code_erreur :level), on=:code_erreur) begin
			coalesce.(0)
		end
	else
		@rtransform! nestor :level = 0
	end

	@label! nestor begin
		:erreur = COL_ERREUR_NESTOR
		:type_marqueur = COL_TYPE_MARQUEUR
		:level = COL_NIVEAU_ERREUR_NESTOR
		:nb_erreur = COL_QUANTITE
		:nb_non_vu = COL_NON_VU
		:nb_en_attente = COL_EN_ATTENTE
		:nb_modifie = COL_MODIFIE
		:nb_valide = COL_VALIDE
		:nb_erreur_masque = COL_QUANTITE_MASQUE
		:nb_non_vu_masque = COL_NON_VU_MASQUE
		:nb_en_attente_masque = COL_EN_ATTENTE_MASQUE
		:nb_modifie_masque = COL_MODIFIE_MASQUE
		:nb_valide_masque = COL_VALIDE_MASQUE
	end 
	@select nestor :erreur :type_marqueur :level :nb_erreur :nb_non_vu :nb_en_attente :nb_modifie :nb_valide :nb_erreur_masque :nb_non_vu_masque :nb_en_attente_masque :nb_modifie_masque :nb_valide_masque
end

# erreur, service, uma, nb_erreur
function get_nestor_uma(site,data,structures,regles = nothing, regles_level = nothing)
	nrow(data) === 0 && return DataFrame()
	umas_libelles = unique(@select structures :UMA :LIBELLE_UMA)
	uma_libelle = combine(groupby(umas_libelles[Not(ismissing.(umas_libelles[:,:LIBELLE_UMA])),:],:UMA),:LIBELLE_UMA => first => :LIBELLE_UMA)

	data = rename(data, Dict(:uma => :UMA))
	# TO FIX : pourquoi la ligne suivante ne fonctionne pas vs la ligne au dessus (si regles != nothing, data contient :UMA au lieu de :uma)
	# @rename! data :UMA = :uma

	# X libellés UMA
	nestor_burma = leftjoin(data, uma_libelle, on=:UMA)

	# fixing service of uma with uh closed
	nestor_burma = leftjoin(nestor_burma,unique(structures[Not(ismissing.(structures[:,:SERVICE])),[:UMA,:UMA_LIB,:SERVICE]]), on= :UMA)
	nestor_burma[!,:UMA] = string.(nestor_burma.UMA," - ",nestor_burma.UMA_LIB)

	# add nestor erreur libelle and cleanup + sort
	nestor_burma = @chain leftjoin(get_libelles_nestor(site), (@select nestor_burma Not(:libelle)), on = :code_erreur) begin
		@rtransform begin
			:erreur = :code_erreur * " - " * :libelle
			:etat = ismissing(:etat) ? "" : :etat
			:UMA = ismissing(:UMA) ? " " : :UMA
			:SERVICE = ismissing(:SERVICE) ? " " : :SERVICE
		end
		coalesce.(0)
		sort([:UMA,order(:nb_erreur,rev=true)])
	end
	 
	if(regles !== nothing)
		nestor_burma = nestor_burma[[r in regles for r in nestor_burma.code_erreur],:]
	end

	# ajout niveau / priorité erreurs 
	if !isnothing(regles_level)
		regles_level_site = @rsubset regles_level :site_tri == site
		nestor_burma = @chain leftjoin(nestor_burma, (@select regles_level_site :code_erreur :level), on=:code_erreur) begin
			coalesce.(0)
		end
	else
		@rtransform! nestor_burma :level = 0
	end

	# NEW à l'UMA ne prendre que les erreurs / UMA sur lesquelles des erreurs sont actives (ou masque active) (et dans le futur ajouter les UMA sur lesquelles des erreus ont été actives)
	nestor_burma = @rsubset nestor_burma :nb_erreur > 0 || :nb_erreur_masque > 0

	@label! nestor_burma begin
		:erreur = COL_ERREUR_NESTOR
		:type_marqueur = COL_TYPE_MARQUEUR
		:level = COL_NIVEAU_ERREUR_NESTOR
		:nb_erreur = COL_QUANTITE
		:nb_non_vu = COL_NON_VU
		:nb_en_attente = COL_EN_ATTENTE
		:nb_modifie = COL_MODIFIE
		:nb_valide = COL_VALIDE
		:nb_erreur_masque = COL_QUANTITE_MASQUE
		:nb_non_vu_masque = COL_NON_VU_MASQUE
		:nb_en_attente_masque = COL_EN_ATTENTE_MASQUE
		:nb_modifie_masque = COL_MODIFIE_MASQUE
		:nb_valide_masque = COL_VALIDE_MASQUE
	end
	@select nestor_burma :SERVICE :UMA :erreur :type_marqueur :level :nb_erreur :nb_non_vu :nb_en_attente :nb_modifie :nb_valide :nb_erreur_masque :nb_non_vu_masque :nb_en_attente_masque :nb_modifie_masque :nb_valide_masque
end

# ---- Actes

function get_actes_operatoire_v3(interventions)
	if nrow(interventions) == 0
		return DataFrame()
	end
	transform!(interventions, :lib_service => ByRow( l -> ismissing(l) ? "" : replace(l, "&eacute;" => "é")))

	@label! interventions begin 
		:etat = "Etat"
		:visibilite = "Visibilité"
		:lib_service = COL_SERVICE
		:date_intervention = "Date inter."
		:lib_intervention = "Libellé intervention"
		:ipp = :IPP
		:nda = :NDA
		:ghm = :GHM
		:heure_entree_salle = "Entrée salle"
		:heure_sortie_salle = "Sortie salle"
		:chirurgien = "Chirurgien"
		:anesthesiste = "Anesthésiste"
		:commentaires = "Commentaires"
	end
	@select interventions :etat :visibilite :lib_service :date_intervention :lib_intervention :ipp :nda :ghm :heure_entree_salle :heure_sortie_salle :chirurgien :anesthesiste :commentaires 
end

# ---- GDS

function get_gds(rum_var_gds_missing, rum_fact_externe)
	if nrow(rum_var_gds_missing) > 0
		rum_var_gds_missing = @chain rum_var_gds_missing begin
			@rtransform begin 
				:ERREUR = "241"
				:ERREUR_LIB = "Variable GDS nombre d'interventions attendue mais non renseignée"
				:GHM = :GHM * " - " * :GHM_LIB
				:DR_RUM = coalesce(:DR_RUM,"")
			end
			@select :ERREUR :ERREUR_LIB :TYPSEJ :NDA :NAS :DDS_RSS :UMA :GHM :DP_RUM :DR_RUM
			@rename begin
				:DATE = :DDS_RSS
				:DP = :DP_RUM
				:DR = :DR_RUM
			end
		end
	else
		rum_var_gds_missing = DataFrame()
	end
	if nrow(rum_fact_externe) > 0
		rum_fact_externe = @chain rum_fact_externe begin
			@rtransform begin 
				:ERREUR = "242"
				:ERREUR_LIB = "Séjour à facturer en externe"
				:GHM = :GHM * " - " * :GHM_LIB
				:DR_RUM = coalesce(:DR_RUM,"")
			end
			@select :ERREUR :ERREUR_LIB :TYPSEJ :NDA :NAS :DDS_RSS :UMA :GHM :DP_RUM :DR_RUM
			@rename begin
				:DATE = :DDS_RSS
				:DP = :DP_RUM
				:DR = :DR_RUM
			end
		end
	else
		rum_fact_externe = DataFrame()
	end
	gds = vcat(rum_var_gds_missing,rum_fact_externe)
	return nrow(gds) == 0 ? gds : @orderby gds	:ERREUR :UMA :DATE
end

# ---- Compute

# info_remontee = get_info_remontee(Date(now())) 
# site = "LRB"
# dsn_simpa = "simpa_$(lowercase(site))"
# structures = get_structures(site,dsn_simpa,info_remontee)

function compute_exh(site, force, recipients_group, remontee, to)
	@info "compute_exh for $site, force = $force, recipients_group = $recipients_group, remontee = $remontee"

	dsn_simpa = "simpa_" * lowercase(site)
	site = uppercase(site);

	# choix de la remontee en fonction de la date et du parametre remontee
	date = Date(now())
	is_lundi = false
	is_jeudi = false
	if ismissing(remontee)
		is_lundi = is_monday(date)
		is_jeudi = is_thursday(date)
		is_lendemain_remontee = is_day_after_remontee(date)
		info_remontee = is_lendemain_remontee == false ? get_info_remontee(date) : get_info_remontee(date - Day(1))
	else
		info_remontee = get_info_remontee(remontee)
		if isnothing(info_remontee)
			@info "unknown remontee, exiting..."
			return
		end
		date = info_remontee.remontee + Day(1)
		is_lendemain_remontee = true
	end

	is_last_week_before_remontee = (-7 <= (date - info_remontee.remontee).value <= 1)

	if force == false && is_lundi == false && is_jeudi == false && is_lendemain_remontee == false && is_last_week_before_remontee == false
		@info "pas un lundi, un lendemain de remontee ou un envoi manuel (> julia exh.jl force), exiting..."
		return
	end

	remontee = info_remontee.intitule
	@info "generating exhaustivité for $remontee $site"

	@info "getting structures from SIMPA x SIRIUS ($dsn_simpa)"
	@timeit to "STRUCTURES @SIMPA x SIRIUS" begin
		structures = get_structures(site,dsn_simpa,info_remontee)
	end
	@pt structures

	@info "getting episode sans groupage from SIMPA ($dsn_simpa)"
	epi_non_groupes_raw = query_episode_sans_groupage(dsn_simpa,info_remontee)
	rum_manquant = get_RUM_manquants(epi_non_groupes_raw,structures)
	@pt rum_manquant

	@info "getting exhaustivité from SIMPA ($dsn_simpa)"
	@timeit to "EXH @SIMPA" begin

		exh_raw_data = query_exh(dsn_simpa,info_remontee)
		months = get_months(info_remontee, true)
		exh_data = get_exhaustivite(exh_raw_data,months,structures)
		@pt exh_data

		activite_rss_data_hc =  @chain exh_raw_data begin
			@rsubset (:MOIS ∈ months) && (:TYDOS == "A")
			@rtransform :TYDOS = "HC"
			unique()
			@by [:TYDOS,:MOIS] :nb_rss = (length ∘ unique)(:NDA)
			unstack(:MOIS,:TYDOS,:nb_rss)
		end

		activite_rss_data_hp =  @chain exh_raw_data begin
			@rsubset (:MOIS ∈ months) && (:TYDOS !== "A")
			@rtransform :TYDOS = "HP"
			@by [:TYDOS,:MOIS] :nb_rss = (length)(:NDA)
			unstack(:MOIS,:TYDOS,:nb_rss)
		end

		@pt activite_rss_data_hc
		@pt activite_rss_data_hp
		
		activite_rss_data = @chain innerjoin(activite_rss_data_hc, activite_rss_data_hp, on=:MOIS) begin
			@orderby :MOIS
			@rtransform :TOTAL = :HC + :HP
			@label! begin
				:MOIS = "Mois"
				:HC = "RSS HC"
				:HP = "RSS HP"
				:TOTAL = "RSS Total"
			end
		end
		@pt activite_rss_data

		@info "calculating manquant mensuel from SIMPA data"
		manquant_mensuel_data = get_exhaustivite_mensuelle(exh_raw_data,months,structures,"manquant")

		@info "calculating activite mensuel from SIMPA data"
		activite_mensuel_data = get_exhaustivite_mensuelle(exh_raw_data,months,structures,"attendu")
	end

	@info "getting 90z from SIMPA ($dsn_simpa)"
	@timeit to "90Z @SIMPA" begin
		cmd90_data = query_90z(dsn_simpa, info_remontee)
		# FIX for unicode (\x12 ) in FG 128 libellé breaking excel
		(nrow(cmd90_data) > 0) && @rtransform! cmd90_data :ERR_GROUPAGE_LIB = replace(:ERR_GROUPAGE_LIB,"\x12"=>"")
		current_cmd90_data = get_90z_current(cmd90_data,info_remontee)
	end

	@info "getting RSS non groupés from SIMPA ($dsn_simpa)"
	@timeit to "RSS ERREURS @SIMPA" begin
		rss_non_groupes_data = query_RSS_non_groupes(dsn_simpa, info_remontee)
		# current_rss_non_groupes_data = get_RSS_non_groupes_current(rss_non_groupes_data,info_remontee)
	end

	@info "loading current site PAQ rules"
	@timeit to "load PAQ rules" begin
		regles_paq = get_regles_paq()
		regles_paq_level = get_regles_paq_level(regles_paq)
		regles_paq_site = regles_paq[(regles_paq.site_tri .== site),:regles_nestor][1]
	end

	@info "getting date MAJ from Infomed ($site)"
	@timeit to "DATE MAJ @INFOMED" begin
		maj_infomed = query_maj_infomed(site)
		date_maj_infomed = nrow(maj_infomed) == 0 ? "-" : first(@rsubset maj_infomed :table_column == "v_sejours.date_last").max_date[1:16]
		delai_maj_infomed = date_maj_infomed !== "-" ? (Date(now()) - Date(date_maj_infomed[1:10],"yyyy-mm-dd")).value : "?"
		date_maj_infomed_pretty = date_maj_infomed !== "-" ? Dates.format(DateTime(date_maj_infomed[1:16],"yyyy-mm-dd HH:MM"),"dd/mm/yyyy HH:MM") : date_maj_infomed
	end

	@info "getting nestor from Infomed"
	@timeit to "NESTOR @INFOMED" begin
		nestor_raw_data_v3 = query_nestor_v3(site,info_remontee)
		nestor_data = get_nestor(site,nestor_raw_data_v3.nestor,nothing,regles_paq_level)
		nestor_uma_data = get_nestor_uma(site,nestor_raw_data_v3.nestor_uma,structures,nothing,regles_paq_level)

		@info "filtering PAQ from Infomed data"
		paq_data_v3 = get_nestor(site,nestor_raw_data_v3.nestor,regles_paq_site,regles_paq_level)
		paq_uma_data_v3 = get_nestor_uma(site,nestor_raw_data_v3.nestor_uma,structures,regles_paq_site,regles_paq_level)
	end

	@info "getting actes operatoires from Infomed ($site)"
	@timeit to "ITV @INFOMED" begin
		actes_raw_data_v3 = query_actes_operatoires_v3(site,info_remontee)
		actes_data_v3 = get_actes_operatoire_v3(actes_raw_data_v3)
	end

	# LAMBDA
	info_remontee_lamda = get_info_remontee_lambda(date)

	@info "[LAMDA] getting structures from SIMPA x SIRIUS ($dsn_simpa)"
	structures_lamda = get_structures(site,dsn_simpa,info_remontee_lamda)
	@pt structures_lamda

	@info "[LAMDA] getting exhaustivité from SIMPA ($dsn_simpa)"
	@timeit to "EXH LAMDA @SIMPA" begin
		exh_raw_data_lamda = query_exh(dsn_simpa,info_remontee_lamda)
		months_lamda = get_months(info_remontee_lamda, true)
		exh_data_lamda = get_exhaustivite(exh_raw_data_lamda,months_lamda,structures_lamda)
		@pt exh_data_lamda

		@info "calculating manquant mensuel from SIMPA data"
		manquant_mensuel_data_lamda = get_exhaustivite_mensuelle(exh_raw_data_lamda,months_lamda,structures_lamda,"manquant")
	end

	@info "getting 90z from SIMPA ($dsn_simpa)"
	@timeit to "90Z LAMDA @SIMPA" begin
		cmd90_data_lamda = query_90z(dsn_simpa, info_remontee_lamda)
		# FIX for unicode (\x12 ) in FG 128 libellé breaking excel
		(nrow(cmd90_data_lamda) > 0) && @rtransform! cmd90_data_lamda :ERR_GROUPAGE_LIB = replace(:ERR_GROUPAGE_LIB,"\x12"=>"")
	end

	@info "getting RSS non groupés from SIMPA ($dsn_simpa)"
	@timeit to "RSS ERREURS LAMDA @SIMPA" begin
		rss_non_groupes_data_lamda = query_RSS_non_groupes(dsn_simpa, info_remontee_lamda)
	end
	# FIN LAMBDA

	# GDS
	@timeit to "GDS @SIMPA" begin
		rum_var_gds_missing = query_gds_rum_241_var_gds_missing(dsn_simpa,info_remontee)
		rum_fact_externe = query_gds_rum_242_a_facturer_externe(dsn_simpa,info_remontee)
		gds = get_gds(rum_var_gds_missing, rum_fact_externe)

		gds_by_fg = nrow(gds) == 0 ? DataFrame() : @chain gds begin
			@rtransform :MOIS = :DATE[1:4] * :DATE[6:7]
			@rtransform :CURRENT = :MOIS == string(info_remontee.id)
			@by :ERREUR begin
				:nb_nas = (length ∘ unique)(:NAS)
				:nb_nas_current = count(==(true),:CURRENT)
			end
		end
	end

	@info "creating .XLSX output file from template"
	@timeit to "save XLSX" begin
		output_name = "exh_$(site)_$(Dates.format(now(),DATE_FORMAT_FILE)).xlsx"
		output_path = joinpath(OUTPUT_FOLDER,output_name)
		cp(TEMPLATE_PATH,output_path)

		# metadata
		@label! exh_data begin
			:SERVICE = COL_SERVICE
			:MODE_HOSPIT = COL_MODE_HOSPIT
			:attendu = COL_RESUMES_ATTENDUS
			:present = COL_RESUMES_LIES
			:manquant = COL_RESUMES_MANQUANTS
			:pourcentage = COL_TAUX_EXHAUSTIVITE
		end

		@label! exh_data_lamda begin
			:SERVICE = COL_SERVICE
			:MODE_HOSPIT = COL_MODE_HOSPIT
			:attendu = COL_RESUMES_ATTENDUS
			:present = COL_RESUMES_LIES
			:manquant = COL_RESUMES_MANQUANTS
			:pourcentage = COL_TAUX_EXHAUSTIVITE
		end 

		@label! manquant_mensuel_data begin
			:SERVICE = COL_SERVICE
			:MODE_HOSPIT = COL_MODE_HOSPIT
		end 

		@label! manquant_mensuel_data_lamda begin
			:SERVICE = COL_SERVICE
			:MODE_HOSPIT = COL_MODE_HOSPIT
		end 

		@label! activite_mensuel_data begin
			:SERVICE = COL_SERVICE
			:MODE_HOSPIT = COL_MODE_HOSPIT
		end

		if nrow(gds) > 0
			@label! gds begin
				:ERREUR = "Erreur FG"
				:ERREUR_LIB = "Libellé Erreur"
				:DATE = "Date"
			end
		end

		@info "filling the sheets & saving output file: $output_path"
		XLSX.openxlsx(output_path, mode="rw") do xf
			i = 1
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "EXH")
			exh_data = @select exh_data :SERVICE :MODE_HOSPIT :UMA :attendu :manquant :pourcentage
			XLSX.writetable!(sheet, collect(DataFrames.eachcol(exh_data)), labels(exh_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "MANQUANT")
			nrow(manquant_mensuel_data) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(manquant_mensuel_data)), labels(manquant_mensuel_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "90Z")
			nrow(cmd90_data) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(cmd90_data)), DataFrames.names(cmd90_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "RSS ERREUR")
			nrow(rss_non_groupes_data) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(rss_non_groupes_data)), DataFrames.names(rss_non_groupes_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "RUM MANQUANT")
			nrow(rum_manquant) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(rum_manquant)), DataFrames.names(rum_manquant))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "GDS")
			nrow(gds) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(gds)), labels(gds))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "PAQ")
			nrow(paq_data_v3) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(paq_data_v3)), labels(paq_data_v3))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "PAQ UMA")
			nrow(paq_uma_data_v3) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(paq_uma_data_v3)), labels(paq_uma_data_v3))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "NESTOR")
			nrow(nestor_data) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(nestor_data)), labels(nestor_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "NESTOR UMA")
			nrow(nestor_uma_data) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(nestor_uma_data)), labels(nestor_uma_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "ACTES")
			nrow(actes_data_v3) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(actes_data_v3)), labels(actes_data_v3))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "ACTIVITE")
			nrow(activite_mensuel_data) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(activite_mensuel_data)), labels(activite_mensuel_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "RSS")
			nrow(activite_rss_data) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(activite_rss_data)), labels(activite_rss_data))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "STRUCTURES")
			transform!(structures,:UMA => ByRow(c -> string(c)) => :UMA)
			sort!(structures,[:UMA])
			XLSX.writetable!(sheet, collect(DataFrames.eachcol(structures)), DataFrames.names(structures))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "EXH LAMDA")
			exh_data_lamda = @select exh_data_lamda :SERVICE :MODE_HOSPIT :UMA :attendu :manquant :pourcentage
			XLSX.writetable!(sheet, collect(DataFrames.eachcol(exh_data_lamda)), labels(exh_data_lamda))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "MANQUANT LAMDA")
			nrow(manquant_mensuel_data_lamda) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(manquant_mensuel_data_lamda)), labels(manquant_mensuel_data_lamda))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "90Z LAMDA")
			nrow(cmd90_data_lamda) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(cmd90_data_lamda)), DataFrames.names(cmd90_data_lamda))
			sheet = xf[i+=1]
			XLSX.rename!(sheet, "RSS ERREUR LAMDA")
			nrow(rss_non_groupes_data_lamda) > 0 && XLSX.writetable!(sheet, collect(DataFrames.eachcol(rss_non_groupes_data_lamda)), DataFrames.names(rss_non_groupes_data_lamda))
		end	
	end

	@timeit to "mail" begin

		recipients = RECIPIENTS_GROUPS[recipients_group]
		@info "preparing the mail for those recipients = $recipients"
		
		attachment_path = output_path
		date_remontee = Dates.format(info_remontee.remontee,DATE_FORMAT_FR)
		days_before_remontee = string((info_remontee.remontee - today()).value)
		periode = info_remontee.periode

		count_attendu = sum(exh_data.attendu)
		count_attendu_hp = sum(exh_data[(exh_data[:,:MODE_HOSPIT] .=== "P"), :attendu])
		count_attendu_hc = sum(exh_data[(exh_data[:,:MODE_HOSPIT] .=== "C"), :attendu])
		count_manquant = sum(exh_data.manquant)
		count_manquant_hp = sum(exh_data[(exh_data[:,:MODE_HOSPIT] .=== "P"), :manquant])
		count_manquant_hc = sum(exh_data[(exh_data[:,:MODE_HOSPIT] .=== "C"), :manquant])

		percent_exh = round(((count_attendu - count_manquant) / count_attendu) * 100; digits=2)
		current_count_attendu, current_count_manquant, current_percent_exh, current_count_attendu_hp, current_count_attendu_hc, current_count_manquant_hp, current_count_manquant_hc = get_exh_current_month(exh_raw_data,info_remontee,structures)

		count_sejour_90z = nrow(cmd90_data) > 0 ? length(unique(cmd90_data.NAS)) : 0
		current_count_90z = nrow(current_cmd90_data)
		current_count_sejour_90z = current_count_90z > 0 ? length(unique(current_cmd90_data.NAS)) : 0

		count_rss_non_groupes = 0;
		current_count_rss_non_groupes = 0;
		current_count_sejours_rss_non_groupes = 0;
		if (nrow(rss_non_groupes_data) > 0)
			tmp_rng = rss_non_groupes_data[rss_non_groupes_data.PROBLEME .== "Groupage",:]
			count_rss_non_groupes = nrow(tmp_rng) > 0 ? length(unique(tmp_rng.NAS)) : 0
			tmp_current_rng = get_RSS_non_groupes_current(tmp_rng,info_remontee)
			current_count_rss_non_groupes = nrow(tmp_current_rng)
			current_count_sejours_rss_non_groupes = current_count_rss_non_groupes > 0 ? length(unique(tmp_current_rng.NAS)) : 0
		end

		count_rss_hc = sum(activite_rss_data.HC)
		count_rss_hp = sum(activite_rss_data.HP)
		count_rss = count_rss_hc + count_rss_hp

		current_activite_rss_data = @subset activite_rss_data (:MOIS .== info_remontee.id)
		current_count_rss_hc = sum(current_activite_rss_data.HC)
		current_count_rss_hp = sum(current_activite_rss_data.HP)
		current_count_rss = current_count_rss_hc + current_count_rss_hp

		any_paq = nrow(paq_data_v3) > 0
		count_paq_non_vu_v3 = any_paq ? sum(paq_data_v3.nb_non_vu) : 0 # FIX 2024-0723
		count_paq_en_attente_v3 = any_paq ? sum(paq_data_v3.nb_en_attente) : 0
		count_paq_modifie_v3 = any_paq ? sum(paq_data_v3.nb_modifie) : 0
		count_paq_valide_v3 = any_paq ? sum(paq_data_v3.nb_valide) : 0
		count_paq_non_vu_masque_v3 = any_paq ? sum(paq_data_v3.nb_non_vu_masque) : 0
		count_paq_en_attente_masque_v3 = any_paq ? sum(paq_data_v3.nb_en_attente_masque) : 0
		count_paq_modifie_masque_v3 = any_paq ? sum(paq_data_v3.nb_modifie_masque) : 0
		count_paq_valide_masque_v3 = any_paq ? sum(paq_data_v3.nb_valide_masque) : 0

		any_nestor = nrow(nestor_data) > 0
		count_nestor_non_vu_v3 = any_nestor ? sum(nestor_data.nb_non_vu) : 0
		count_nestor_en_attente_v3 = any_nestor ? sum(nestor_data.nb_en_attente) : 0
		count_nestor_modifie_v3 = any_nestor ? sum(nestor_data.nb_modifie) : 0
		count_nestor_valide_v3 = any_nestor ? sum(nestor_data.nb_valide) : 0
		count_nestor_non_vu_masque_v3 = any_nestor ? sum(nestor_data.nb_non_vu_masque) : 0
		count_nestor_en_attente_masque_v3 = any_nestor ? sum(nestor_data.nb_en_attente_masque) : 0
		count_nestor_modifie_masque_v3 = any_nestor ? sum(nestor_data.nb_modifie_masque) : 0
		count_nestor_valide_masque_v3 = any_nestor ? sum(nestor_data.nb_valide_masque) : 0
		
		count_actes_v3 = nrow(actes_data_v3)
		count_actes_with_NDA_v3_visible = count_actes_v3 == 0 ? 0 : nrow(actes_data_v3[(.!ismissing.(actes_data_v3.nda) .& (actes_data_v3.visibilite .=== "visible")),:])
		count_actes_with_NDA_v3_masque = count_actes_v3 == 0 ? 0 : nrow(actes_data_v3[(.!ismissing.(actes_data_v3.nda) .& (actes_data_v3.visibilite .=== "masquée")),:])
		count_actes_without_NDA_v3_visible = count_actes_v3 == 0 ? 0 : nrow(actes_data_v3[(ismissing.(actes_data_v3.nda) .& (actes_data_v3.visibilite .=== "visible")),:])
		count_actes_without_NDA_v3_masque = count_actes_v3 == 0 ? 0 : nrow(actes_data_v3[(ismissing.(actes_data_v3.nda) .& (actes_data_v3.visibilite .=== "masquée")),:])
		
		count_fg241 = (nrow(gds_by_fg) == 0 || nrow(@rsubset gds_by_fg :ERREUR == "241") == 0 ) ? 0 : first((@rsubset gds_by_fg :ERREUR == "241").nb_nas)
		count_fg242 = (nrow(gds_by_fg) == 0 || nrow(@rsubset gds_by_fg :ERREUR == "242") == 0 ) ? 0 : first((@rsubset gds_by_fg :ERREUR == "242").nb_nas)
		current_count_fg241 = (nrow(gds_by_fg) == 0 || nrow(@rsubset gds_by_fg :ERREUR == "241") == 0 ) ? 0 : first((@rsubset gds_by_fg :ERREUR == "241").nb_nas_current)
		current_count_fg242 = (nrow(gds_by_fg) == 0 || nrow(@rsubset gds_by_fg :ERREUR == "242") == 0 ) ? 0 : first((@rsubset gds_by_fg :ERREUR == "242").nb_nas_current)

		# Table EXH
		tdb_exh = DataFrame(
			periode=[],
			attendus=[], 
			attendus_hc=[], 
			attendus_hp=[], 
			manquants=[], 
			manquants_hc=[], 
			manquants_hp=[], 
			exhaustivite=[], 
			cmd90=[],
			non_groupes=[],
			fg_241=[],
			fg_242=[],
			activite=[],
			activite_hc=[],
			activite_hp=[]
			# ADD GDS (taux_plein,intermediaire,externe,var_gds_na)
		)
		push!(tdb_exh,("Cumul",count_attendu,count_attendu_hc,count_attendu_hp,count_manquant,count_manquant_hc,count_manquant_hp,string(percent_exh,"%"),count_sejour_90z,count_rss_non_groupes,count_fg241,count_fg242,count_rss,count_rss_hc,count_rss_hp))
		push!(tdb_exh,(remontee,current_count_attendu,current_count_attendu_hc,current_count_attendu_hp,current_count_manquant,current_count_manquant_hc,current_count_manquant_hp,string(current_percent_exh,"%"),current_count_sejour_90z, current_count_sejours_rss_non_groupes,current_count_fg241,current_count_fg242,current_count_rss,current_count_rss_hc,current_count_rss_hp))

		if mod(info_remontee.id,100) > 1 
			before_percent_exh = round((((count_attendu - current_count_attendu) - (count_manquant - current_count_manquant)) / (count_attendu - current_count_attendu)) * 100; digits=2)
			push!(tdb_exh,(
				get_remontees_before(info_remontee),
				count_attendu - current_count_attendu, 
				count_attendu_hc - current_count_attendu_hc, 
				count_attendu_hp - current_count_attendu_hp, 
				count_manquant - current_count_manquant, 
				count_manquant_hc - current_count_manquant_hc, 
				count_manquant_hp - current_count_manquant_hp, 
				string(before_percent_exh,"%"), 
				count_sejour_90z - current_count_sejour_90z, 
				count_rss_non_groupes - current_count_sejours_rss_non_groupes,
				count_fg241 - current_count_fg241,
				count_fg242 - current_count_fg242,
				count_rss - current_count_rss,
				count_rss_hc - current_count_rss_hc,
				count_rss_hp - current_count_rss_hp,
			))
		end
		
		tdb_exh = @select tdb_exh :periode :manquants :manquants_hc :manquants_hp :attendus :attendus_hc :attendus_hp :exhaustivite :cmd90 :non_groupes :fg_241 :fg_242 :activite :activite_hc :activite_hp
		@label! tdb_exh begin
			:periode = "Exhaustivité"
			:manquants = "Manquants"
			:manquants_hc = "&#x25B8;HC"
			:manquants_hp = "&#x25B8;HP"
			:attendus = "Attendus"
			:attendus_hc = "&#x25B8;HC"
			:attendus_hp = "&#x25B8;HP"
			:exhaustivite = "% Exhaustivité"
			:cmd90 = "90Z"
			:non_groupes = "Non Groupés"
			:fg_241 = "FG 241"
			:fg_242 = "FG 242"
			:activite = "Activité"
			:activite_hc = "&#x25B8;HC"
			:activite_hp = "&#x25B8;HP"
		end

		# Table PAQ
		tdb_paq = DataFrame(
			type=[],
			non_vu=[], 
			en_attente=[], 
			modifie=[], 
			valide=[]
		)
		push!(tdb_paq,("Nestor PAQ visibles",count_paq_non_vu_v3,count_paq_en_attente_v3,count_paq_modifie_v3,count_paq_valide_v3))
		push!(tdb_paq,("Nestor visibles",count_nestor_non_vu_v3,count_nestor_en_attente_v3,count_nestor_modifie_v3,count_nestor_valide_v3))
		push!(tdb_paq,("Nestor PAQ masquées",count_paq_non_vu_masque_v3,count_paq_en_attente_masque_v3,count_paq_modifie_masque_v3,count_paq_valide_masque_v3))
		push!(tdb_paq,("Nestor masquées",count_nestor_non_vu_masque_v3,count_nestor_en_attente_masque_v3,count_nestor_modifie_masque_v3,count_nestor_valide_masque_v3))
		
		@label! tdb_paq begin 
			:type = "Erreurs Nestor Infomed"
			:non_vu = "Non Vues"
			:en_attente = "En Attente"
			:modifie = "Vérifiées & Modifiées"
			:valide = "Vérifiées & Non-Modifiées"
		end

		# Table ACTES
		tdb_actes = DataFrame(
			type=[],
			actes_with_NDA=[], 
			actes_without_NDA=[]
		)
		push!(tdb_actes,("Infomed v3 visibles",count_actes_with_NDA_v3_visible,count_actes_without_NDA_v3_visible))
		push!(tdb_actes,("Infomed v3 masquées",count_actes_with_NDA_v3_masque,count_actes_without_NDA_v3_masque))
		
		@label! tdb_actes begin 
			:type = "Interventions sans Actes"
			:actes_with_NDA = "en Hospit (avec NDA)"
			:actes_without_NDA = "en Externe? (sans NDA)"
		end

		hl_site = HtmlHighlighter((data, i, j) -> (j == 1), HtmlDecoration(font_weight = "bold"));
		hl_v2 = HtmlHighlighter((data, i, j) -> (i == 0) && (j ∈ [3,4,6,7,12,13]), HtmlDecoration(color = "black"));

		html_table_exh = pretty_table(HTML,tdb_exh; header = labels(tdb_exh), show_subheader = false, alignment = :c, highlighters=(hl_site,hl_v2), table_class="table1", allow_html_in_cells = true)
		html_table_paq = pretty_table(HTML,tdb_paq; header = labels(tdb_paq), show_subheader = false, alignment = :c, highlighters=(hl_site), table_class="table2")
		html_table_actes = pretty_table(HTML,tdb_actes; header = labels(tdb_actes), show_subheader = false, alignment = :c, highlighters=(hl_site), table_class="table3")

		bg_color = "#3D5E79" 
		bg_color_2 = "#FF8102"
		bg_color_3 = "#55AC29"

		css_table = """
		<style>
			table, td, th {
				border-collapse: collapse;
				font-family: Calibri, sans-serif;
				vertical-align: middle;
				font-size: 13px;
			}
			td, th { padding: 6px !important; }
			thead { color: white; }

			.table1, .table1 td, .table1 th{ border: 1px solid $bg_color; }
			.table1 thead { background-color: $bg_color; }

			.table2, .table2 td, .table2 th{ border: 1px solid $bg_color_2; }
			.table2 thead { background-color: $bg_color_2; }

			.table3, .table3 td, .table3 th{ border: 1px solid $bg_color_3; }
			.table3 thead { background-color: $bg_color_3; }
		</style>
		"""

		nownow = Dates.format(now(),DATE_FORMAT_FR)
		title = is_lendemain_remontee == true ? "Résultat remontée MCO $site $periode ($nownow)" : "PAQ & exhaustivité MCO $site $remontee ($nownow)"
		# title = preview ? "[DEV] $title" : "$title"
		d_day = is_lendemain_remontee == true ? "" : " (J-<strong>$days_before_remontee</strong>)"

		mail = """
		$(css_table)
		<div style='font-family:Calibri,sans-serif;'>Bonjour,<br><br>
			Veuillez trouver ci-jointe l'exhaustivité du codage MCO pour la remontée <strong>$remontee $site</strong> du <strong>$date_remontee</strong>$d_day, ainsi que l'état du traitement des erreurs Nestor retenues pour le Plan d'Assurance Qualité 2024, de source SIMPA/Infomed/Sirius.<br><br>

			$(html_table_exh.content)<br>
			$(html_table_paq.content)<br>
			$(html_table_actes.content)<br>
			<strong>dernière MAJ des séjours Infomed</strong> : $(date_maj_infomed_pretty) (J+$(delai_maj_infomed))<br>
			<hr>
			mail généré par le <strong>DIM</strong> du <strong>GHU AP-HP. Nord</strong> - le $(Dates.format(now(),"dd/mm/yyyy à HH:MM"))
		</div>
		"""

		send_mail(recipients[dsn_simpa], title, mail, attachment_path)
	end

	@timeit to "save output" begin
		html_output_name = string("exh_",dsn_simpa,"_",Dates.format(now(),DATE_FORMAT_FILE),".html")
		html_output_path = joinpath(OUTPUT_FOLDER,html_output_name)
		write(html_output_path, mail);

		if recipients_group == MAIL_RECIPIENTS_GROUP_ALL
			final_output_path = joinpath("/home/save_exh",output_name)
			@info "copying excel file to $final_output_path..."
			cp(output_path,final_output_path)

			final_html_output_path = joinpath("/home/save_exh",html_output_name)
			@info "copying mail file to $final_html_output_path..."
			cp(html_output_path,final_html_output_path)
		end

		@info "deleting temp excel file..."
		rm(output_path)
		@info "deleting temp mail file..."
		rm(html_output_path)
	end
end

function recipients_from_args(args)
	(("preview" ∈ args) || ("obscure" ∈ args) || ("dev" ∈ args) || ("rouge" ∈ args)) && return MAIL_RECIPIENTS_GROUP_DEV
	(("bleu" ∈ args) || ("bleue" ∈ args)) && return MAIL_RECIPIENTS_GROUP_MIMING
	("jv" ∈ args) && return MAIL_RECIPIENTS_GROUP_JV
	return MAIL_RECIPIENTS_GROUP_ALL
end


function (@main)(ARGS)
	sites = ["cch"]
	force_arg = false
	recipients_arg = MAIL_RECIPIENTS_GROUP_ALL
	remontee_arg = missing
	if length(ARGS) > 0
		force_arg = "force" ∈ ARGS
		recipients_arg = recipients_from_args(ARGS)
		sites_arg = intersect(lowercase.(ARGS),ALL_SITES)
		t = filter(x -> !isnothing(x),match.(r"(?<remontee>\d{4}M\d{2})$",ARGS))
		remontee_arg = length(t) == 0 ? missing : string(first(t)[:remontee])
		if length(sites_arg) > 0
			sites = sites_arg
		end
	end

	to = TimerOutput()
	@timeit to "EXH GHU" begin
		for site in sites
			@timeit to "EXH $site" compute_exh(site,force_arg,recipients_arg,remontee_arg,to)
		end
	end

	# change display column size to avoid truncating section names in timeroutput table display & log via @info 
	ENV["COLUMNS"] = 240
	# show(to)
	@info to
end
