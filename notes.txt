import streamlit as st
import pandas as pd
import subprocess
import os
from io import BytesIO
from datetime import datetime

def test_oracle_connection(user, password, tns_alias):
    test_sql = "C:/Users/4251352/Portail_outils/SQL/test_connexion.sql"

    cmd = f"sqlplus -S {user}/{password}@{tns_alias} @{test_sql}"

    try:
        result = subprocess.run(
            cmd,
            shell=True,
            stdout=subprocess.PIPE,
            text=True,
            timeout=3
        )
        output = result.stdout.strip()
        return "1" in output

    except Exception:
        return False

def main():
    SQL_PATH = "C:/Users/4251352/Portail_outils/SQL/contigus.sql"
    CSV_PATH = "C:/Users/4251352/Portail_outils/data/resultat.csv"
    OUTPUT_PATH = "C:/Users/4251352/Portail_outils/data/doublons.xlsx"

    st.set_page_config(page_title="Analyse des S√©jours Contigus & Doublons", layout="centered")

    st.title("D√©tection des Doublons, Contigus et Chevauchements")
    st.markdown("Cet outil ex√©cute la requ√™te SQL, analyse les s√©jours et g√©n√®re un fichier Excel structur√©.")


    with st.form("connexion"):
        st.subheader("Connexion Oracle")
        user = st.text_input("üë§ Nom d'utilisateur Oracle :", value="")
        password = st.text_input("üîë Mot de passe :", type="password")
        execute_sql = st.checkbox("Ex√©cuter la requ√™te SQL avant analyse", value=False)
        submitted = st.form_submit_button("üöÄ Lancer le traitement")

    if submitted:
        if not user or not password:
            st.error("Veuillez renseigner vos identifiants Oracle.")
            st.stop()

        if execute_sql:
            tns_alias = "SIP1CCH.WORLD"
            with st.spinner("üîê Test de connexion Oracle..."):
                is_ok = test_oracle_connection(user, password, tns_alias)
            if not is_ok:
                st.error("Connexion Oracle √©chou√©e : Identifiants incorrects.")
                st.stop()
            with st.spinner("üß† Ex√©cution de la requ√™te SQL, veuillez patienter..."):
                try:
                    cmd = f'sqlplus {user}/{password}@{tns_alias} @{SQL_PATH}'
                    subprocess.run(cmd, shell=True)
                except Exception as e:
                    st.error(f"Erreur lor de l'ex√©cution SQL : {e}")
                    return
            st.success("‚úÖ Requ√™te SQL termin√©e et fichier CSV g√©n√©r√©.")
            st.divider()

        if not os.path.exists(CSV_PATH):
            st.error(f"Le fichier {CSV_PATH} n'existe pas. Veuillez ex√©cuter la requ√™te SQL.")
            st.stop()

        with st.spinner("üîé Analyse des s√©jours en cours..."):
            try:
                df = pd.read_csv(CSV_PATH, sep=';', skip_blank_lines=True, dtype=str, encoding='latin-1')
            except Exception as e:
                st.error(f"Erreur lecture CSV : {e}")
                return
            
            try:
                df = df.dropna(how='all')
                df.columns = [col.strip().upper() for col in df.columns]

                expected_cols = ["IPP", "DATE_NAISSANCE", "NDA", "UMA", "GHM", "DATE_ENTREE", "DATE_SORTIE"]
                if df.shape[1] >= len(expected_cols):
                    df.columns = expected_cols + [f"COL_EXTRA_{i}" for i in range(df.shape[1] - len(expected_cols))]

                df['IPP'] = df['IPP'].astype(str).str.strip()
                df['UMA'] = df['UMA'].fillna("").astype(str).str.strip()
                df['NDA'] = df['NDA'].astype(str).str.strip()
                df['GHM'] = df["GHM"].fillna("").astype(str).str.strip()
                df['DATE_ENTREE'] = pd.to_datetime(df['DATE_ENTREE'], dayfirst=True, errors='coerce')
                df['DATE_SORTIE'] = pd.to_datetime(df['DATE_SORTIE'], dayfirst=True, errors='coerce')

                df = df[~df["UMA"].isin(["540","543"])]

                df = df.dropna(subset=["DATE_ENTREE", "DATE_SORTIE", "UMA", "IPP"])
                df = df.sort_values(['IPP', 'DATE_ENTREE', 'DATE_SORTIE']).reset_index(drop=True)
            except Exception as e:
                st.error(f"Erreur nettoyage donn√©es : {e}")
                return

            rows = []
            try:
                for ipp, group in df.groupby('IPP', sort=False):
                    g = group.reset_index(drop=True)
                    n = len(g)
                    for i in range(n):
                        nda1, uma1, ghm1, de1, ds1 = g.loc[i, ['NDA', 'UMA', 'GHM', 'DATE_ENTREE', 'DATE_SORTIE']]
                        j = i + 1
                        while j < n:
                            de2 = g.loc[j, 'DATE_ENTREE']
                            if pd.isna(de2):
                                j += 1
                                continue
                            if de2 > ds1 and de2 != ds1:
                                break
                            nda2, uma2, ghm2, ds2 = g.loc[j, ['NDA', 'UMA', 'GHM', 'DATE_SORTIE']]
                            if nda1 == nda2:
                                j += 1
                                continue

                            rel = None
                            if (uma1 == uma2) and (de1 == de2) and (ds1 == ds2):
                                rel = "VRAI_DOUBLON"
                            elif (uma1 != uma2) and (de1 == de2) and (ds1 == ds2):
                                rel = "DOUBLON_0_NUIT"
                            else:
                                root1 = ghm1.strip()
                                root2 = ghm2.strip()
                                valid_ghm = (
                                    root1 not in ("", "NAN", "None", "NONE") and
                                    root2 not in ("", "NAN", "None", "NONE") and
                                    len(root1) >= 5 and len(root2) >= 5
                                )
                                if ( (uma1 != uma2) and ((ds1 == de2) or (ds2 == de1)) and valid_ghm and root1[:5] == root2[:5] ):
                                    rel = "CONTIGUS"
                                elif (uma1 != uma2) and (de1 < ds2) and (ds1 > de2):
                                    rel = "CHEVAUCHEMENT"

                            if rel:
                                rows.append({
                                    "IPP": ipp,
                                    "DATE_NAISSANCE": g.loc[i, 'DATE_NAISSANCE'],

                                    "NDA1": nda1,
                                    "UMA1": uma1,
                                    "GHM1": ghm1,
                                    "DATEE1": de1,
                                    "DATES1": ds1,

                                    "NDA2": nda2,
                                    "UMA2": uma2,
                                    "GHM2": ghm2,
                                    "DATEE2": de2,
                                    "DATES2": ds2,
                                    "TYPE_RELATION": rel
                                })
                            j += 1
            except Exception as e:
                st.error(f"Erreur d√©tection relations : {e}")
                return

            try:
                res = pd.DataFrame(rows).drop_duplicates()
                res = res.reset_index(drop=True)
                res["PAIR_ID"] = res.index + 1

                def build_rows_instead_of_columns(df_rel, keep_ghm: bool):
                    left_cols = {
                        "IPP": "IPP",
                        "DATE_NAISSANCE": "DATE_NAISSANCE",
                        "NDA": "NDA1",
                        "UMA": "UMA1",
                        "DATE_ENTREE": "DATEE1",
                        "DATE_SORTIE": "DATES1",
                        "PAIR_ID": "PAIR_ID"
                    }
                    if keep_ghm:
                        left_cols["GHM"] = "GHM1"

                    df1 = df_rel[list(left_cols.values())].copy()
                    df1.columns = list(left_cols.keys())
                    df1["LIGNE"] = 1

                    right_cols = {
                        "IPP": "IPP",
                        "DATE_NAISSANCE": "DATE_NAISSANCE",
                        "NDA": "NDA2",
                        "UMA": "UMA2",
                        "DATE_ENTREE": "DATEE2",
                        "DATE_SORTIE": "DATES2",
                        "PAIR_ID": "PAIR_ID"
                    }
                    if keep_ghm:
                        right_cols["GHM"] = "GHM2"

                    df2 = df_rel[list(right_cols.values())].copy()
                    df2.columns = list(right_cols.keys())
                    df2["LIGNE"] = 2

                    out = pd.concat([df1, df2], ignore_index=True)

                    for c in ["DATE_ENTREE", "DATE_SORTIE"]:
                        out[c] = pd.to_datetime(out[c], errors="coerce").dt.strftime("%d/%m/%Y")

                    out["COMMENTAIRE"] = ""

                    if keep_ghm:
                        out = out[["IPP", "DATE_NAISSANCE", "NDA", "UMA", "GHM",
                                "DATE_ENTREE", "DATE_SORTIE", "COMMENTAIRE"]]
                    else:
                        out = out[["IPP", "DATE_NAISSANCE", "NDA", "UMA",
                                "DATE_ENTREE", "DATE_SORTIE", "COMMENTAIRE"]]

                    out = out.sort_values(["IPP"]).reset_index(drop=True)
                    return out

                with pd.ExcelWriter(OUTPUT_PATH, engine="openpyxl") as writer:
                    for groupe in ["VRAI_DOUBLON", "DOUBLON_0_NUIT", "CONTIGUS", "CHEVAUCHEMENT"]:
                        subset = res[res["TYPE_RELATION"] == groupe].copy()

                        subset = subset.drop(columns=["TYPE_RELATION"], errors="ignore")

                        keep_ghm = (groupe == "CONTIGUS")

                        if subset.empty:
                            if keep_ghm:
                                df_to_write = pd.DataFrame([{
                                    "IPP": "N/A", "DATE_NAISSANCE": "N/A",
                                    "NDA": "N/A", "UMA": "N/A", "GHM": "N/A",
                                    "DATE_ENTREE": "N/A", "DATE_SORTIE": "N/A", "COMMENTAIRE": ""
                                }])
                            else:
                                df_to_write = pd.DataFrame([{
                                    "IPP": "N/A", "DATE_NAISSANCE": "N/A",
                                    "NDA": "N/A", "UMA": "N/A",
                                    "DATE_ENTREE": "N/A", "DATE_SORTIE": "N/A", "COMMENTAIRE": ""
                                }])
                        else:
                            df_to_write = build_rows_instead_of_columns(subset, keep_ghm=keep_ghm)

                        df_to_write.to_excel(writer, sheet_name=groupe, index=False)

                        ws = writer.sheets[groupe]
                        for i, col in enumerate(df_to_write.columns):
                            max_len = max(df_to_write[col].astype(str).map(len).max(), len(col)) + 2
                            ws.column_dimensions[ws.cell(row=1, column=i + 1).column_letter].width = max_len

            except Exception as e:
                st.error(f"Erreur √©criture Excel : {e}")
                return

        st.success("‚úÖ Analyse termin√©e avec succ√®s !")

        with open(OUTPUT_PATH, "rb") as f:
            st.download_button(
                label="üì• T√©l√©charger le fichier Excel",
                data=f,
                file_name=f"doublons_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
