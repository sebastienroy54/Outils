import streamlit as st
import pandas as pd
import subprocess
import time
from pathlib import Path
from datetime import datetime
from openpyxl import load_workbook
from shutil import copyfile
import re
from openpyxl.styles import Border, Side, Alignment, Font
from collections import defaultdict

BASE_DIR = Path("C:/Users/4251352/Portail_outils")
DATA_DIR = BASE_DIR / "data"
SQL_DIR = BASE_DIR / "SQL"
PATRON_TIM_XLSX = DATA_DIR / "tableau_rum_tim.xlsx"   # source pour construire le dictionnaire TIM
PATRON_FILL_XLSX = DATA_DIR / "Tableau.xlsx"          # patron Ã  copier et remplir

TNS_MAP = {
    "CCH": "SIP1CCH.WORLD",
    "BRC": "SIP1BRC.WORLD",
    "HTD": "SIP_HTD.WORLD"
}

def safe_show_exception(e):
    st.session_state.last_exception_str = str(e)
    st.error("Une erreur est survenue. VÃ©rifiez vos fichiers ou contactez le support.")
    if "show_exception" not in st.session_state:
        st.session_state.show_exception = False
    st.session_state.show_exception = st.checkbox("Afficher dÃ©tails techniques", value=st.session_state.show_exception)
    if st.session_state.show_exception and "last_exception_str" in st.session_state:
        st.code(st.session_state.last_exception_str)

def run_sqlplus_and_wait(cmd, timeout=30):
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    start = time.time()
    output = ""
    while True:
        if proc.poll() is not None:
            out, _ = proc.communicate()
            output += (out or "")
            break
        if time.time() - start > timeout:
            proc.kill()
            raise TimeoutError("Timeout lors de l'exÃ©cution sqlplus.")
        time.sleep(0.1)
    return output

def build_sql_spool_rum(site_label, file_spool_path, mode, month, year):
    if mode == "mois":
        start = f"01/{int(month):02d}/{year}"
        end_expr = f"LAST_DAY(TO_DATE('01/{int(month):02d}/{year}','DD/MM/YYYY'))"
        where_clause = (f"D8EEUE BETWEEN TO_DATE('{start}','DD/MM/YYYY') AND {end_expr}")
    else:
        start = f"01/01/{year}"
        end_expr = f"LAST_DAY(TO_DATE('01/{int(month):02d}/{year}','DD/MM/YYYY'))"
        where_clause = (f"D8SOUE >= TO_DATE('{start}','DD/MM/YYYY') AND D8EEUE <= {end_expr}")
    sql = f"""
SET HEADING OFF
SET FEEDBACK OFF
SET PAGESIZE 0
SET LINESIZE 2000
SET TRIMSPOOL ON
spool {file_spool_path}
SELECT CDURM_P || ';' || COUNT(*)
FROM EPI
WHERE {where_clause}
GROUP BY CDURM_P;
spool off
exit;
"""
    return sql

def read_spool_csv_to_df(spool_path):
    p = Path(spool_path)
    if not p.exists():
        return pd.DataFrame(columns=["UMA", "COUNT"])
    try:
        df = pd.read_csv(p, sep=';', header=None, dtype=str, names=["UMA", "COUNT"], engine="python")
        df["UMA"] = df["UMA"].astype(str).str.strip()
        df["COUNT"] = pd.to_numeric(df["COUNT"].astype(str).str.strip().replace("", "0"), errors="coerce").fillna(0).astype(int)
        return df
    except Exception:
        lines = p.read_text(encoding="utf-8", errors="ignore").splitlines()
        rows = []
        for line in lines:
            if ";" in line:
                a, b = line.split(";", 1)
                rows.append({"UMA": a.strip(), "COUNT": int(b.strip() or 0)})
        return pd.DataFrame(rows)

# --- Parsing UMA/TIM from patron: now includes libelle and type ---
def extract_uma_code_by_space(uma):
    if not isinstance(uma, str):
        return ""
    s = uma.strip()
    return s.split(" ", 1)[0].strip() if s else ""

def split_tims(cell):
    if not isinstance(cell, str):
        return []
    cell = cell.strip()
    if cell.lower() in {"nan", "none", ""}:
        return []
    parts = re.split(r'[/;,|]+', cell)
    return [p.strip() for p in parts if p.strip()]

def normalize_dmu(raw):
    if not isinstance(raw, str):
        return ""
    s = raw.strip()
    return s.split(" ", 1)[0].strip() if s else ""

def build_tim_uma_dict(patron_path):
    """
    Retourne dictionnaire enrichi :
    TIM -> site -> DMU -> [ {code, libelle, type} , ... ]
    """
    df = pd.read_excel(patron_path, engine="openpyxl", dtype=str)
    df.columns = [c.strip() for c in df.columns]

    for col in ["Site", "UMA", "DMU"]:
        if col not in df.columns:
            raise KeyError(f"Colonne manquante : {col}")

    tim_ref_col = "TIM RÃ©fÃ©rent" if "TIM RÃ©fÃ©rent" in df.columns else None
    relance_col = "Relance" if "Relance" in df.columns else None
    type_col = "Type" if "Type" in df.columns else None

    def clean_tim(tim):
        if not isinstance(tim, str):
            return ""
        s = tim.replace("\u200b", "") \
               .replace("\ufeff", "") \
               .replace("\u00a0", " ") \
               .replace("\u200e", "") \
               .replace("\u200f", "")
        s = re.sub(r'\s+', ' ', s).strip()
        return s

    result = {}
    for _, row in df.iterrows():
        raw_uma_full = row.get("UMA", "")
        if not isinstance(raw_uma_full, str) or raw_uma_full.strip() == "" or raw_uma_full.startswith("Total DMU"):
            continue
        uma_code = extract_uma_code_by_space(raw_uma_full)
        uma_libelle = raw_uma_full.strip()
        site = str(row.get("Site", "")).strip() or "UNKNOWN"
        raw_dmu = row.get("DMU", "")
        dmu_code = normalize_dmu(raw_dmu)
        if dmu_code == "":
            continue

        uma_type_raw = row.get(type_col, "") if type_col else ""
        uma_type = (str(uma_type_raw).strip().upper() if isinstance(uma_type_raw, str) else "")
        if uma_type not in {"HC", "HDJ"}:
            # fallback : si pas de type, prÃ©sumer HC (ou tu peux forcer Ã  HDJ selon rÃ¨gles)
            uma_type = "HC"

        tims = []
        if tim_ref_col:
            tims += split_tims(row.get(tim_ref_col, ""))
        if relance_col:
            tims += split_tims(row.get(relance_col, ""))

        if not tims:
            continue

        uma_obj = {"code": uma_code, "libelle": uma_libelle, "type": uma_type}
        for tim in tims:
            tim_norm = clean_tim(tim)
            if not tim_norm:
                continue
            result.setdefault(tim_norm, {}).setdefault(site, {}).setdefault(dmu_code, []).append(uma_obj)

    # Ensure UMA lists are unique per DMU (by code) and sorted
    def uniq_sort_umas(list_of_umas):
        seen = {}
        for uma in list_of_umas:
            seen.setdefault(uma["code"], uma)  # keep first occ for libelle/type
        out = list(seen.values())
        out.sort(key=lambda x: x["code"])
        return out

    result_listified = {
        tim: {
            site: {dmu: uniq_sort_umas(umas) for dmu, umas in dmus.items()}
            for site, dmus in sites.items()
        }
        for tim, sites in result.items()
    }
    return result_listified

def merge_vertical_conditionnel(ws, col_idx, df_col, start_row, group_col=None):
    """
    Fusion verticale des cellules identiques dans une colonne.
    Si group_col est fourni, fusion seulement si la valeur du groupe est identique.
    """
    if len(df_col) == 0:
        return
    current_val = df_col.iloc[0]
    current_group = group_col.iloc[0] if group_col is not None else None
    start_idx = 0
    for i in range(1, len(df_col)):
        val = df_col.iloc[i]
        group_val = group_col.iloc[i] if group_col is not None else None
        same = (val == current_val) and (group_col is None or group_val == current_group)
        if not same:
            if i - 1 > start_idx:
                ws.merge_cells(start_row=start_row + start_idx, start_column=col_idx,
                               end_row=start_row + i - 1, end_column=col_idx)
            start_idx = i
            current_val = val
            current_group = group_val
    # fusion de la derniÃ¨re sÃ©rie
    if len(df_col) - 1 > start_idx:
        ws.merge_cells(start_row=start_row + start_idx, start_column=col_idx,
                       end_row=start_row + len(df_col) - 1, end_column=col_idx)

def draw_border_lines_for_tim_blocks(ws, start_row, df_sorted, first_col, last_col, site_col_idx=None):
    """
    Trace des bordures horizontales : 
    - haut et bas pour chaque TIM
    - ligne supplÃ©mentaire entre sites si site_col_idx fourni
    """
    thin = Side(border_style="thin", color="000000")
    top_border = Border(top=thin)
    bottom_border = Border(bottom=thin)

    # Bordures TIM
    tim_groups = df_sorted.groupby("TIM").apply(lambda x: (x.index.min(), x.index.max()))
    for tim, (start_idx, end_idx) in tim_groups.items():
        top_row = start_row + start_idx
        bottom_row = start_row + end_idx
        for c in range(first_col, last_col + 1):
            ws.cell(row=top_row, column=c).border = Border(
                left=ws.cell(row=top_row, column=c).border.left,
                right=ws.cell(row=top_row, column=c).border.right,
                top=thin,
                bottom=ws.cell(row=top_row, column=c).border.bottom
            )
            ws.cell(row=bottom_row, column=c).border = Border(
                left=ws.cell(row=bottom_row, column=c).border.left,
                right=ws.cell(row=bottom_row, column=c).border.right,
                top=ws.cell(row=bottom_row, column=c).border.top,
                bottom=thin
            )

    # Bordures entre sites
    if site_col_idx is not None:
        for i in range(1, len(df_sorted)):
            if df_sorted["SITE"].iloc[i] != df_sorted["SITE"].iloc[i - 1]:
                row = start_row + i
                for c in range(first_col, last_col + 1):
                    ws.cell(row=row, column=c).border = Border(
                        left=ws.cell(row=row, column=c).border.left,
                        right=ws.cell(row=row, column=c).border.right,
                        top=thin,
                        bottom=ws.cell(row=row, column=c).border.bottom
                    )

def apply_uma_exceptions(df_patron):
    """
    GÃ¨re les exceptions UMA spÃ©cifiques :
    - 150 HTD : RUM codÃ©s TIM = 0 (codÃ©s par cliniciens)
    - 040X CCH : transfÃ©rÃ© de codÃ©s Ã  relancÃ©s
    - 561C, 591C, 591J CCH : codÃ©s par TIM, non cliniciens
    """
    # UMA 150 HTD
    mask_150 = (df_patron["UMA_code"] == "150") & (df_patron["SITE"] == "HTD") & (df_patron["UMA_type"] == "HC")
    df_patron.loc[mask_150, ["RUM_codes_mois", "RUM_codes_cum"]] = 0.0

    # UMA 040X CCH : transfÃ©rer des codÃ©s aux relancÃ©s
    mask_040X = (df_patron["UMA_code"].str.startswith("040X")) & (df_patron["SITE"] == "CCH")
    df_patron.loc[mask_040X, ["RUM_rel_mois", "RUM_rel_cum"]] = df_patron.loc[mask_040X, ["RUM_codes_mois", "RUM_codes_cum"]].values
    df_patron.loc[mask_040X, ["RUM_codes_mois", "RUM_codes_cum"]] = 0.0

    # UMA 561C, 591C, 591J CCH : codÃ©s par TIM
    for uma in ["561C", "591C", "591J"]:
        mask = (df_patron["UMA_code"] == uma) & (df_patron["SITE"] == "CCH") & (df_patron["UMA_type"] == "HDJ")
        df_patron.loc[mask, ["RUM_codes_mois", "RUM_codes_cum"]] = df_patron.loc[mask, ["RUM_rel_mois", "RUM_rel_cum"]].values
        df_patron.loc[mask, ["RUM_rel_mois", "RUM_rel_cum"]] = 0.0

    return df_patron

def write_copy_with_values_to_patron(df, patron_path):
    """
    Ã‰crit le dataframe dans le patron Excel et retourne un BytesIO pour tÃ©lÃ©chargement Streamlit
    """
    from io import BytesIO
    copy_path = patron_path  # pas besoin de copier sur disque
    wb = load_workbook(filename=str(copy_path))
    ws = wb.active

    # repÃ©rer header_row
    header_row = None
    for r in range(1, 30):
        values = [(ws.cell(row=r, column=c).value or "").strip().lower() for c in range(1, ws.max_column + 1)]
        if "tim" in values and "site" in values:
            header_row = r
            break
    if not header_row:
        header_row = 1

    # mapping des en-tÃªtes
    name_to_col = {str(ws.cell(row=header_row, column=c).value).strip().lower(): c
                   for c in range(1, ws.max_column + 1) if ws.cell(row=header_row, column=c).value}

    # assignation colonnes
    col_tim = name_to_col.get("tim")
    col_site = name_to_col.get("site")
    col_uma_hc = name_to_col.get("uma hc")
    col_rum_codes_mois = name_to_col.get("rum codes mois")
    col_rum_codes_cum = name_to_col.get("rum codes cumul")
    col_uma_hdj = name_to_col.get("uma hdj")
    col_dmu = name_to_col.get("dmu")
    col_rum_rel_mois = name_to_col.get("rum rel mois")
    col_rum_rel_cum = name_to_col.get("rum rel cum")

    start = header_row + 1

    df_sorted = df.sort_values(by=["TIM", "SITE", "DMU", "UMA_code"]).reset_index(drop=True)

    for idx, row in df_sorted.iterrows():
        excel_row = start + idx
        ws.cell(row=excel_row, column=col_tim).value = row["TIM"]
        ws.cell(row=excel_row, column=col_site).value = row["SITE"]
        if row["UMA_type"] == "HC":
            ws.cell(row=excel_row, column=col_uma_hc).value = row["UMA_libelle"]
            ws.cell(row=excel_row, column=col_rum_codes_mois).value = int(round(row["RUM_codes_mois"]))
            ws.cell(row=excel_row, column=col_rum_codes_cum).value = int(round(row["RUM_codes_cum"]))
        else:
            ws.cell(row=excel_row, column=col_uma_hdj).value = row["UMA_libelle"]
            ws.cell(row=excel_row, column=col_dmu).value = row["DMU"]
            ws.cell(row=excel_row, column=col_rum_rel_mois).value = int(round(row["RUM_rel_mois"]))
            ws.cell(row=excel_row, column=col_rum_rel_cum).value = int(round(row["RUM_rel_cum"]))

    # Fusion TIM / SITE / DMU
    merge_vertical_conditionnel(ws, col_tim, df_sorted["TIM"], start)
    merge_vertical_conditionnel(ws, col_site, df_sorted["SITE"], start, group_col=df_sorted["TIM"])
    merge_vertical_conditionnel(ws, col_dmu, df_sorted["DMU"], start, group_col=df_sorted["TIM"])

    # Bordures
    draw_border_lines_for_tim_blocks(ws, start, df_sorted, 1, ws.max_column, site_col_idx=col_site)

    # Align center
    for idx, row in df_sorted.iterrows():
        excel_row = start + idx
        for c in [col_tim, col_site, col_dmu]:
            ws.cell(row=excel_row, column=c).alignment = Alignment(horizontal="center", vertical="center")

    # TIM bold
    tim_positions = df_sorted.groupby("TIM").apply(lambda x: (x.index.min(), x.index.max()))
    for tim, (start_idx, _) in tim_positions.items():
        excel_row = start + start_idx
        ws.cell(row=excel_row, column=col_tim).font = Font(bold=True)

    # exporter en mÃ©moire
    output = BytesIO()
    wb.save(output)
    output.seek(0)
    return output

# ----------------- Page RUM (nouvelle logique) -----------------
def page_rum():
    st.title("Remplissage RUM â€” TIM")
    if "oracle_connected" not in st.session_state or not st.session_state.oracle_connected:
        st.error("Vous devez d'abord vous connecter sur la page Connexion.")
        return

    mois = st.selectbox("Choisir le mois", list(range(1, 13)), index=datetime.now().month - 1)
    annees = list(range(2013, datetime.now().year + 1))
    annee = st.selectbox("Choisir l'annÃ©e", annees, index=len(annees)-1)
    bouton = st.button("Lancer le traitement RUM")
    st.markdown("**Remarque :** le script va interroger les 3 bases (CCH, BRC, HTD) et gÃ©nÃ©rer un tableau par TIM.")
    if not bouton:
        return

    try:
        progress = st.progress(0)
        progress.progress(5)

        # Construction dictionnaire TIM -> site -> DMU -> [uma_obj]
        tim_dict = build_tim_uma_dict(PATRON_TIM_XLSX)

        # UMA_WEIGHTS: exceptions de pondÃ©ration (code UMA, nom TIM) -> poids
        UMA_WEIGHTS = {
            ("130", "Clara HEBRARD"): 1/3,
            ("130", "Maria Louisa ESTEVES"): 2/3
        }

        # Construire DataFrame : une ligne par UMA (libellÃ©) pour chaque TIM/site/DMU
        rows = []
        for tim, sites in tim_dict.items():
            for site, dmus in sites.items():
                for dmu, umas in dmus.items():
                    for uma in umas:
                        rows.append({
                            "TIM": tim,
                            "SITE": site,
                            "DMU": dmu,
                            "UMA_code": uma["code"],
                            "UMA_libelle": uma["libelle"],
                            "UMA_type": uma["type"],
                            # colonnes sÃ©parÃ©es pour HC vs HDJ
                            "RUM_codes_mois": 0.0,
                            "RUM_codes_cum": 0.0,
                            "RUM_rel_mois": 0.0,
                            "RUM_rel_cum": 0.0
                        })
        df_patron = pd.DataFrame(rows)
        progress.progress(30)

        # compter combien de TIM rÃ©fÃ©rencent chaque UMA_code
        uma_to_tim_count = defaultdict(int)
        for tim, sites in tim_dict.items():
            for site, dmus in sites.items():
                for dmu, umas in dmus.items():
                    for uma in umas:
                        uma_to_tim_count[uma["code"]] += 1

        # ExÃ©cution SQL (par site) pour obtenir df_m et df_c (UMA code -> COUNT)
        for idx_site, (site_label, tns) in enumerate(TNS_MAP.items()):
            spool_mois = DATA_DIR / f"RUM_MOIS_{site_label}.csv"
            spool_cum = DATA_DIR / f"RUM_CUMULE_{site_label}.csv"
            sql_mois = build_sql_spool_rum(site_label, str(spool_mois), "mois", mois, annee)
            sql_cum = build_sql_spool_rum(site_label, str(spool_cum), "cumule", mois, annee)
            tmp_sql_mois = SQL_DIR / f"rum_mois_{site_label}.sql"
            tmp_sql_cum = SQL_DIR / f"rum_cumule_{site_label}.sql"
            tmp_sql_mois.write_text(sql_mois, encoding="utf-8")
            tmp_sql_cum.write_text(sql_cum, encoding="utf-8")

            cmd_mois = f"sqlplus -S {st.session_state.oracle_user}/{st.session_state.oracle_password}@{tns} @{tmp_sql_mois}"
            cmd_cum = f"sqlplus -S {st.session_state.oracle_user}/{st.session_state.oracle_password}@{tns} @{tmp_sql_cum}"
            out_m = run_sqlplus_and_wait(cmd_mois, timeout=60)
            out_c = run_sqlplus_and_wait(cmd_cum, timeout=60)
            df_m = read_spool_csv_to_df(spool_mois)
            df_c = read_spool_csv_to_df(spool_cum)

            # Pour chaque UMA dans tim_dict, rÃ©cupÃ©rer sa base et appliquer pondÃ©ration / type
            for tim, sites in tim_dict.items():
                for site, dmus in sites.items():
                    for dmu, umas in dmus.items():
                        for uma in umas:
                            uma_code = uma["code"]
                            uma_type = uma["type"]
                            # base counts (0 si absent)
                            base_m = df_m.loc[df_m["UMA"] == uma_code, "COUNT"].sum()
                            base_c = df_c.loc[df_c["UMA"] == uma_code, "COUNT"].sum()
                            # poids personnalisÃ© sinon 1 / nTIM
                            default_count = uma_to_tim_count.get(uma_code, 1)
                            weight = UMA_WEIGHTS.get((uma_code, tim), 1.0 / default_count if default_count > 0 else 1.0)
                            assigned_m = base_m * weight
                            assigned_c = base_c * weight

                            # ajouter aux lignes correspondantes dans df_patron
                            mask = (df_patron["TIM"] == tim) & (df_patron["SITE"] == site) & (df_patron["DMU"] == dmu) & (df_patron["UMA_code"] == uma_code)
                            if uma_type == "HC":
                                df_patron.loc[mask, "RUM_codes_mois"] += assigned_m
                                df_patron.loc[mask, "RUM_codes_cum"] += assigned_c
                            else:  # HDJ
                                df_patron.loc[mask, "RUM_rel_mois"] += assigned_m
                                df_patron.loc[mask, "RUM_rel_cum"] += assigned_c

            try:
                tmp_sql_mois.unlink()
                tmp_sql_cum.unlink()
            except:
                pass

            progress.progress(30 + idx_site * 20)

        # Round numeric columns to integers for output
        for col in ["RUM_codes_mois", "RUM_codes_cum", "RUM_rel_mois", "RUM_rel_cum"]:
            if col in df_patron.columns:
                df_patron[col] = df_patron[col].fillna(0.0).astype(float)

        # Ã‰crire dans le patron de sortie
        output = write_copy_with_values_to_patron(df_patron, PATRON_FILL_XLSX)
        #sortie_path = DATA_DIR / f"tableau_rum_tim_rempli_{mois:02d}_{annee}.xlsx"
        progress.progress(100)

        st.success(f"Traitement terminÃ© â€” fichier prÃªt au tÃ©lÃ©chargement")

        st.download_button(
            "TÃ©lÃ©charger le fichier rempli",
            data=output,
            file_name=f"tableau_rum_tim_rempli_{mois:02d}_{annee}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        safe_show_exception(e)

# ----------------- Page Connexion + session + main (inchangÃ©s) -----------------
def page_connexion():
    st.title("Connexion Oracle")
    if not st.session_state.logged_in:
        with st.form("connexion"):
            st.subheader("Connexion Oracle")
            user = st.text_input("ðŸ‘¤ Nom d'utilisateur Oracle :", key="conn_user")
            password = st.text_input("ðŸ”‘ Mot de passe :", type="password", key="conn_pwd")
            submitted = st.form_submit_button("ðŸš€ Se connecter")

        if submitted:
            if not user or not password:
                st.error("Veuillez renseigner vos identifiants Oracle.")
                return
            try:
                st.info("Test de connexion...")
                tns_alias = TNS_MAP["CCH"]
                test_sql_path = SQL_DIR / "test_connexion.sql"
                test_sql_path.write_text("select 1 from dual;\nexit;", encoding="utf-8")
                cmd = f"sqlplus -S {user}/{password}@{tns_alias} @{test_sql_path}"
                out = run_sqlplus_and_wait(cmd, timeout=3)
                if "1" in out:
                    st.session_state.oracle_connected = True
                    st.session_state.logged_in = True
                    st.session_state.oracle_user = user
                    st.session_state.oracle_password = password
                    st.session_state.page = "rum"
                    st.rerun()
                else:
                    st.error("Connexion Ã©chouÃ©e. VÃ©rifiez vos identifiants Oracle.")
            except Exception as e:
                safe_show_exception(e)
            finally:
                try:
                    test_sql_path.unlink()
                except:
                    pass
    else:
        st.success("Connexion active.")
        if st.button("âž¡ Aller Ã  la page RUM"):
            st.session_state.page = "rum"
            st.rerun()

def ensure_session_vars():
    defaults = {
        "logged_in": False,
        "oracle_connected": False,
        "page": "connexion",
        "oracle_user": "",
        "oracle_password": "",
        "last_exception_str": "",
        "show_exception": False
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

def main():
    st.set_page_config(page_title="RUM TIM", layout="centered")
    ensure_session_vars()
    if st.session_state.page == "connexion":
        page_connexion()
    elif st.session_state.page == "rum":
        if not st.session_state.logged_in:
            st.session_state.page = "connexion"
            st.rerun()
        page_rum()
    else:
        st.session_state.page = "connexion"
        st.rerun()

if __name__ == "__main__":
    main()
