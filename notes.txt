import streamlit as st
import pandas as pd
import numpy as np
import subprocess
import time
import random
from pathlib import Path
from datetime import datetime
from openpyxl import load_workbook
from copy import copy
import re
from openpyxl.styles import Border, Side, Alignment, Font
from collections import defaultdict

BASE_DIR = Path("C:/Users/4251352/Portail_outils")
DATA_DIR = BASE_DIR / "data"
SQL_DIR = BASE_DIR / "SQL"
PATRON_TIM_XLSX = DATA_DIR / "tableau_rum_tim.xlsx"   # source pour construire le dictionnaire TIM
PATRON_FILL_XLSX = DATA_DIR / "Tableau.xlsx"          # patron √† copier et remplir

TNS_MAP = {
    "CCH": "SIP1CCH.WORLD",
    "BRC": "SIP1BRC.WORLD",
    "HTD": "SIP_HTD.WORLD"
}

def safe_show_exception(e):
    st.session_state.last_exception_str = str(e)
    st.error("Une erreur est survenue. V√©rifiez vos fichiers ou contactez le support.")
    if "show_exception" not in st.session_state:
        st.session_state.show_exception = False
    st.session_state.show_exception = st.checkbox("Afficher d√©tails techniques", value=st.session_state.show_exception)
    if st.session_state.show_exception and "last_exception_str" in st.session_state:
        st.code(st.session_state.last_exception_str)

def run_sqlplus_and_wait(cmd, timeout=30):
    proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
    start = time.time()
    output = ""
    while True:
        if proc.poll() is not None:
            out, _ = proc.communicate()
            output += (out or "")
            break
        if time.time() - start > timeout:
            proc.kill()
            raise TimeoutError("Timeout lors de l'ex√©cution sqlplus.")
        time.sleep(0.1)
    return output

def build_sql_spool_rum(site_label, file_spool_path, mode, month, year):
    if mode == "mois":
        start = f"01/{int(month):02d}/{year}"
        end_expr = f"LAST_DAY(TO_DATE('01/{int(month):02d}/{year}','DD/MM/YYYY'))"
        where_clause = (f"D8EEUE BETWEEN TO_DATE('{start}','DD/MM/YYYY') AND {end_expr}")
    else:
        start = f"01/01/{year}"
        end_expr = f"LAST_DAY(TO_DATE('01/{int(month):02d}/{year}','DD/MM/YYYY'))"
        where_clause = (f"D8SOUE >= TO_DATE('{start}','DD/MM/YYYY') AND D8EEUE <= {end_expr}")
    sql = f"""
SET HEADING OFF
SET FEEDBACK OFF
SET PAGESIZE 0
SET LINESIZE 2000
SET TRIMSPOOL ON
spool {file_spool_path}
SELECT CDURM_P || ';' || COUNT(*)
FROM EPI
WHERE {where_clause}
GROUP BY CDURM_P;
spool off
exit;
"""
    return sql

def read_spool_csv_to_df(spool_path):
    p = Path(spool_path)
    if not p.exists():
        return pd.DataFrame(columns=["UMA", "COUNT"])
    try:
        df = pd.read_csv(p, sep=';', header=None, dtype=str, names=["UMA", "COUNT"], engine="python")
        df["UMA"] = df["UMA"].astype(str).str.strip()
        df["COUNT"] = pd.to_numeric(df["COUNT"].astype(str).str.strip().replace("", "0"), errors="coerce").fillna(0).astype(int)
        return df
    except Exception:
        lines = p.read_text(encoding="utf-8", errors="ignore").splitlines()
        rows = []
        for line in lines:
            if ";" in line:
                a, b = line.split(";", 1)
                rows.append({"UMA": a.strip(), "COUNT": int(b.strip() or 0)})
        return pd.DataFrame(rows)

# --- Parsing UMA/TIM from patron: now includes libelle and type ---
def extract_uma_code_by_space(uma):
    if not isinstance(uma, str):
        return ""
    s = uma.strip()
    return s.split(" ", 1)[0].strip() if s else ""

def split_tims(cell):
    if not isinstance(cell, str):
        return []
    cell = cell.strip()
    if cell.lower() in {"nan", "none", ""}:
        return []
    parts = re.split(r'[/;,|]+', cell)
    return [p.strip() for p in parts if p.strip()]

def normalize_dmu(raw):
    if not isinstance(raw, str):
        return ""
    s = raw.strip()
    return s.split(" ", 1)[0].strip() if s else ""

def build_tim_uma_dict(patron_path):
    print("\n========== BUILD_TIM_UMA_DICT ==========")
    df = pd.read_excel(patron_path, engine="openpyxl", dtype=str)
    df.columns = [c.strip() for c in df.columns]

    for col in ["Site", "UMA", "DMU"]:
        if col not in df.columns:
            raise KeyError(f"Colonne manquante : {col}")

    tim_ref_col = "TIM R√©f√©rent" if "TIM R√©f√©rent" in df.columns else None
    relance_col = "Relance" if "Relance" in df.columns else None
    type_col = "Type" if "Type" in df.columns else None

    result = {}

    print(f"‚ñ∂ Nombre de lignes patron TIM : {len(df)}")
    print(f"‚ñ∂ Colonnes reconnues : {df.columns.tolist()}")

    for idx, row in df.iterrows():

        raw_uma_full = row.get("UMA", "")
        if not isinstance(raw_uma_full, str) or raw_uma_full.strip() == "" or raw_uma_full.startswith("Total DMU"):
            continue

        uma_code = extract_uma_code_by_space(raw_uma_full)
        uma_type_raw = row.get(type_col, "") if type_col else ""
        uma_type = (str(uma_type_raw).strip().upper() if isinstance(uma_type_raw, str) else "")
        if uma_type not in {"HC", "HDJ"}:
            uma_type = "HC"

        site = str(row.get("Site", "")).strip()
        dmu = str(row.get("DMU", "")).split(" ", 1)[0].strip()

        tims = []
        if tim_ref_col: tims += split_tims(row.get(tim_ref_col, ""))
        if relance_col: tims += split_tims(row.get(relance_col, ""))

        if not tims:
            continue

        for tim in tims:
            result.setdefault(tim, {}).setdefault(site, {}).setdefault(dmu, []).append(
                {"code": uma_code, "libelle": raw_uma_full, "type": uma_type}
            )

    print(f"‚ñ∂ TIM trouv√©s : {len(result)}")
    print("=========================================\n")

    return result

def merge_vertical_conditionnel(ws, col_idx, df_col, start_row, group_col=None):
    """
    Fusion verticale des cellules identiques dans une colonne.
    Si group_col est fourni, fusion seulement si la valeur du groupe est identique.
    """
    if len(df_col) == 0:
        return
    current_val = df_col.iloc[0]
    current_group = group_col.iloc[0] if group_col is not None else None
    start_idx = 0
    for i in range(1, len(df_col)):
        val = df_col.iloc[i]
        group_val = group_col.iloc[i] if group_col is not None else None
        same = (val == current_val) and (group_col is None or group_val == current_group)
        if not same:
            if i - 1 > start_idx:
                ws.merge_cells(start_row=start_row + start_idx, start_column=col_idx,
                               end_row=start_row + i - 1, end_column=col_idx)
            start_idx = i
            current_val = val
            current_group = group_val
    # fusion de la derni√®re s√©rie
    if len(df_col) - 1 > start_idx:
        ws.merge_cells(start_row=start_row + start_idx, start_column=col_idx,
                       end_row=start_row + len(df_col) - 1, end_column=col_idx)

def draw_border_lines_for_tim_blocks(ws, start_row, df_sorted, first_col, last_col, site_col_idx=None):
    """
    Trace des bordures horizontales : 
    - haut et bas pour chaque TIM
    - ligne suppl√©mentaire entre sites si site_col_idx fourni
    """
    thin = Side(border_style="thin", color="000000")
    top_border = Border(top=thin)
    bottom_border = Border(bottom=thin)

    # Bordures TIM
    tim_groups = df_sorted.groupby("TIM").apply(lambda x: (x.index.min(), x.index.max()))
    for tim, (start_idx, end_idx) in tim_groups.items():
        top_row = start_row + start_idx
        bottom_row = start_row + end_idx
        for c in range(first_col, last_col + 1):
            ws.cell(row=top_row, column=c).border = Border(
                left=ws.cell(row=top_row, column=c).border.left,
                right=ws.cell(row=top_row, column=c).border.right,
                top=thin,
                bottom=ws.cell(row=top_row, column=c).border.bottom
            )
            ws.cell(row=bottom_row, column=c).border = Border(
                left=ws.cell(row=bottom_row, column=c).border.left,
                right=ws.cell(row=bottom_row, column=c).border.right,
                top=ws.cell(row=bottom_row, column=c).border.top,
                bottom=thin
            )

    # Bordures entre sites
    if site_col_idx is not None:
        for i in range(1, len(df_sorted)):
            if df_sorted["SITE"].iloc[i] != df_sorted["SITE"].iloc[i - 1]:
                row = start_row + i
                for c in range(first_col, last_col + 1):
                    ws.cell(row=row, column=c).border = Border(
                        left=ws.cell(row=row, column=c).border.left,
                        right=ws.cell(row=row, column=c).border.right,
                        top=thin,
                        bottom=ws.cell(row=row, column=c).border.bottom
                    )

def apply_uma_exceptions(df):
    """
    Exceptions UMA bas√©es UNIQUEMENT sur les codes UMA.
    """

    print("\n======= DEBUG APPLY_UMA_EXCEPTIONS =======")

    print("Codes UMA HC pr√©sents dans df_patron (20 max) :", df["UMA_HC_code"].unique()[:20])
    print("Codes UMA HDJ pr√©sents dans df_patron (20 max) :", df["UMA_HDJ_code"].unique()[:20])

    # ========== 1Ô∏è‚É£ 150 HC HTD ==========

    print("\n-- V√©rification des UMA 150 HC sur HTD --")
    debug_150 = df[(df["SITE"]=="HTD") & (df["UMA_HC_code"]=="150")]
    print(debug_150[["TIM","SITE","UMA HC","RUM cod√©s mois"]].head(10))

    mask_150_hc = (df["SITE"] == "HTD") & (df["UMA_HC_code"] == "150")
    mask_cliniciens = df["TIM"] == "Cliniciens"

    if mask_150_hc.any():
        print("[EXC 150 HTD] Lignes trouv√©es :", mask_150_hc.sum())

        val_mois = df.loc[mask_150_hc, "RUM cod√©s mois"].sum()
        val_cum = df.loc[mask_150_hc, "RUM cod√©s cumul√©s"].sum()

        print(f" Somme mois={val_mois}, cumul={val_cum}")

        # Cliniciens ‚Üí cod√©s
        df.loc[mask_cliniciens, "RUM cod√©s mois"] = val_mois
        df.loc[mask_cliniciens, "RUM cod√©s cumul√©s"] = val_cum

        # Autres TIM ‚Üí relanc√©s
        other_tim = mask_150_hc & (~mask_cliniciens)
        df.loc[other_tim, "RUM relanc√©s mois"] = df.loc[other_tim, "RUM cod√©s mois"]
        df.loc[other_tim, "RUM relanc√©s cumul√©s"] = df.loc[other_tim, "RUM cod√©s cumul√©s"]

        # Vider les cod√©s chez eux
        df.loc[other_tim, ["RUM cod√©s mois", "RUM cod√©s cumul√©s"]] = np.nan

    # ========== 2Ô∏è‚É£ 040X HC CCH ==========

    print("\n-- V√©rification des UMA 040X HC sur CCH --")
    debug_040x = df[(df["SITE"]=="CCH") & (df["UMA_HC_code"]=="040X")]
    print(debug_040x[["TIM","SITE","UMA HC","RUM cod√©s mois"]].head(10))

    mask_040x = (df["SITE"] == "CCH") & (df["UMA_HC_code"] == "040X")

    if mask_040x.any():
        print("[EXC 040X CCH] Lignes impact√©es :", mask_040x.sum())

        df.loc[mask_040x, "RUM relanc√©s mois"] = df.loc[mask_040x, "RUM cod√©s mois"]
        df.loc[mask_040x, "RUM relanc√©s cumul√©s"] = df.loc[mask_040x, "RUM cod√©s cumul√©s"]

        df.loc[mask_040x, ["RUM cod√©s mois", "RUM cod√©s cumul√©s"]] = np.nan

    # ========== 3Ô∏è‚É£ HDJ sp√©ciaux ‚Üí cod√©s ==========
    for code in ["561C", "591C", "591J"]:

        print(f"\n-- V√©rification des UMA {code} HDJ sur CCH --")
        debug_sp = df[(df["SITE"]=="CCH") & (df["UMA_HDJ_code"]==code)]
        print(debug_sp[["TIM","SITE","UMA HDJ","RUM relanc√©s mois"]].head(10))

        mask = (df["SITE"] == "CCH") & (df["UMA_HDJ_code"] == code)

        if mask.any():
            print(f"[EXC {code} CCH] Lignes impact√©es :", mask.sum())

            df.loc[mask, "RUM cod√©s mois"] = df.loc[mask, "RUM relanc√©s mois"]
            df.loc[mask, "RUM cod√©s cumul√©s"] = df.loc[mask, "RUM relanc√©s cumul√©s"]

            df.loc[mask, ["RUM relanc√©s mois", "RUM relanc√©s cumul√©s"]] = np.nan

    print("======= FIN APPLY_UMA_EXCEPTIONS =======\n")

    return df

# --- √âcriture Excel ---
def write_copy_with_values_to_patron(df, patron_path):
    from io import BytesIO
    wb = load_workbook(filename=str(patron_path))
    ws = wb.active

    # Header detection
    header_row = None
    for r in range(1, 30):
        values = [(ws.cell(row=r, column=c).value or "").strip().lower() for c in range(1, ws.max_column+1)]
        if "tim" in values and "site" in values:
            header_row = r
            break
    if not header_row:
        header_row = 1

    name_to_col = {str(ws.cell(row=header_row, column=c).value).strip(): c for c in range(1, ws.max_column+1)}

    col_map = {
        "TIM": name_to_col.get("TIM"),
        "SITE": name_to_col.get("SITE"),
        "UMA HC": name_to_col.get("UMA HC"),
        "RUM_codes_mois": name_to_col.get("RUM cod√©s mois"),
        "RUM_codes_cumul√©s": name_to_col.get("RUM cod√©s cumul√©s"),
        "UMA HDJ": name_to_col.get("UMA HDJ"),
        "DMU": name_to_col.get("DMU"),
        "RUM_rel_mois": name_to_col.get("RUM relanc√©s mois"),
        "RUM_rel_cum": name_to_col.get("RUM relanc√©s cumul√©s")
    }

    start = header_row + 1
    df_sorted = df.sort_values(by=["TIM", "SITE", "DMU", "UMA HC", "UMA HDJ"]).reset_index(drop=True)

    # Fill cells
    for idx, row in df_sorted.iterrows():
        excel_row = start + idx
        ws.cell(row=excel_row, column=col_map["TIM"]).value = row["TIM"]
        ws.cell(row=excel_row, column=col_map["SITE"]).value = row["SITE"]
        ws.cell(row=excel_row, column=col_map["DMU"]).value = row["DMU"]

        if row["UMA HC"]:
            ws.cell(row=excel_row, column=col_map["UMA HC"]).value = row["UMA HC"]
            ws.cell(row=excel_row, column=col_map["RUM_codes_mois"]).value = int(row["RUM cod√©s mois"]) if pd.notna(row["RUM cod√©s mois"]) else None
            ws.cell(row=excel_row, column=col_map["RUM_codes_cumul√©s"]).value = int(row["RUM cod√©s cumul√©s"]) if pd.notna(row["RUM cod√©s cumul√©s"]) else None
        if row["UMA HDJ"]:
            ws.cell(row=excel_row, column=col_map["UMA HDJ"]).value = row["UMA HDJ"]
            ws.cell(row=excel_row, column=col_map["RUM_rel_mois"]).value = int(row["RUM relanc√©s mois"]) if pd.notna(row["RUM relanc√©s mois"]) else None
            ws.cell(row=excel_row, column=col_map["RUM_rel_cum"]).value = int(row["RUM relanc√©s cumul√©s"]) if pd.notna(row["RUM relanc√©s cumul√©s"]) else None

    # Fusion et bordures horizontales
    merge_vertical_conditionnel(ws, col_map["TIM"], df_sorted["TIM"], start)
    merge_vertical_conditionnel(ws, col_map["SITE"], df_sorted["SITE"], start, group_col=df_sorted["TIM"])
    merge_vertical_conditionnel(ws, col_map["DMU"], df_sorted["DMU"], start, group_col=df_sorted["TIM"])
    draw_border_lines_for_tim_blocks(ws, start, df_sorted, 1, ws.max_column, site_col_idx=col_map["SITE"])

    # Bordures verticales pour toutes les colonnes
    thin = Side(border_style="thin", color="000000")
    for r in range(1, ws.max_row+1):
        for c in range(1, ws.max_column+1):
            cell = ws.cell(row=r, column=c)
            cell.border = Border(left=thin, right=thin, top=cell.border.top, bottom=cell.border.bottom)

    # Centrage uniquement TIM, SITE, DMU
    for idx, row in df_sorted.iterrows():
        excel_row = start + idx
        for c in [col_map["TIM"], col_map["SITE"], col_map["DMU"]]:
            ws.cell(row=excel_row, column=c).alignment = Alignment(horizontal="center", vertical="center")

    # Mise en gras de tous les noms de TIM (sur les lignes de donn√©es)
    tim_col = col_map["TIM"]
    if tim_col is not None:
        for idx in range(len(df_sorted)):
            excel_row = start + idx
            cell = ws.cell(row=excel_row, column=tim_col)
            old_font = cell.font
            new_font = copy(old_font)
            new_font.bold = True
            cell.font = new_font

    output = BytesIO()
    wb.save(output)
    output.seek(0)
    return output

def page_rum():
    st.title("Remplissage RUM ‚Äî TIM")
    if "oracle_connected" not in st.session_state or not st.session_state.oracle_connected:
        st.error("Vous devez d'abord vous connecter sur la page Connexion.")
        return

    mois = st.selectbox("Choisir le mois", list(range(1, 13)), index=datetime.now().month - 1)
    annees = list(range(2013, datetime.now().year + 1))
    annee = st.selectbox("Choisir l'ann√©e", annees, index=len(annees)-1)
    bouton = st.button("Lancer le traitement RUM")
    st.markdown("**Remarque :** le script va interroger les 3 bases (CCH, BRC, HTD) et g√©n√©rer un tableau par TIM.")
    if not bouton:
        return

    try:
        progress = st.progress(0)
        progress.progress(5)

        # --- 1. Dictionnaire TIM / UMA depuis tableau_rum_tim.xlsx ---
        st.write("üîπ Construction du dictionnaire TIM/UMA...")
        tim_dict = build_tim_uma_dict(PATRON_TIM_XLSX)
        st.write(f"‚úÖ TIM dict construit, {len(tim_dict)} TIM trouv√©s.")

        # Pond√©rations sp√©ciales
        UMA_WEIGHTS = {
            ("130", "Clara HEBRARD"): 1/3,
            ("130", "Maria Louisa ESTEVES"): 2/3
        }

        # --- 2. Construction du df_patron (structure cible) ---
        st.write("üîπ Construction du DataFrame df_patron...")
        rows = []
        for tim, sites in tim_dict.items():
            for site, dmus in sites.items():
                for dmu, umas in dmus.items():
                    for uma in umas:
                        rows.append({
                            "TIM": tim,
                            "SITE": site,
                            "UMA HC": uma["libelle"] if uma["type"] == "HC" else "",
                            "RUM cod√©s mois": 0.0 if uma["type"] == "HC" else np.nan,
                            "RUM cod√©s cumul√©s": 0.0 if uma["type"] == "HC" else np.nan,
                            "UMA HDJ": uma["libelle"] if uma["type"] == "HDJ" else "",
                            "DMU": dmu,
                            "RUM relanc√©s mois": 0.0 if uma["type"] == "HDJ" else np.nan,
                            "RUM relanc√©s cumul√©s": 0.0 if uma["type"] == "HDJ" else np.nan,
                        })
        df_patron = pd.DataFrame(rows)
        st.write(f"‚úÖ df_patron cr√©√© : {df_patron.shape[0]} lignes")

        # DEBUG console
        print("====== DEBUG df_patron INITIAL ======")
        print("Nombre de lignes :", len(df_patron))
        print("Colonnes :", list(df_patron.columns))
        print("Sites pr√©sents dans df_patron :", df_patron["SITE"].unique())
        print("=====================================")

        progress.progress(20)

        # --- 3. Ajout colonnes code UMA pour la correspondance avec les CSV ---
        st.write("üîπ Extraction des codes UMA pour correspondance...")
        df_patron["UMA_HC_code"] = df_patron["UMA HC"].apply(extract_uma_code_by_space)
        df_patron["UMA_HDJ_code"] = df_patron["UMA HDJ"].apply(extract_uma_code_by_space)

        # --- 4. Comptage du nombre de TIM par code UMA (r√©partition des RUM) ---
        st.write("üîπ Comptage du nombre de TIM par code UMA...")
        uma_to_tim_count = defaultdict(int)
        for tim, sites in tim_dict.items():
            for site, dmus in sites.items():
                for dmu, umas in dmus.items():
                    for uma in umas:
                        uma_to_tim_count[uma["code"]] += 1
        st.write(f"‚úÖ UMA counts: {len(uma_to_tim_count)} codes UMA")

        # DEBUG console
        print("====== DEBUG UMA_to_TIM_count (quelques exemples) ======")
        for i, (code, n) in enumerate(uma_to_tim_count.items()):
            if i >= 15:
                break
            print(f"Code UMA {code} -> utilis√© par {n} TIM")
        print("========================================================")

        progress.progress(30)

        # --- 5. Pour chaque site (CCH/BRC/HTD) : lire les CSV + affecter les RUM ---
        for idx_site, (site_label, tns) in enumerate(TNS_MAP.items()):
            st.write(f"üîπ Traitement site {site_label} ({idx_site+1}/{len(TNS_MAP)})")

            # 5.1 SQL + spool
            spool_mois = DATA_DIR / f"RUM_MOIS_{site_label}.csv"
            spool_cum = DATA_DIR / f"RUM_CUMULE_{site_label}.csv"

            sql_mois = build_sql_spool_rum(site_label, str(spool_mois), "mois", mois, annee)
            sql_cum = build_sql_spool_rum(site_label, str(spool_cum), "cumule", mois, annee)

            tmp_sql_mois = SQL_DIR / f"rum_mois_{site_label}.sql"
            tmp_sql_cum = SQL_DIR / f"rum_cumule_{site_label}.sql"

            tmp_sql_mois.write_text(sql_mois, encoding="utf-8")
            tmp_sql_cum.write_text(sql_cum, encoding="utf-8")

            st.write("üì° Lancement sqlplus mois...")
            out_m = run_sqlplus_and_wait(
                f"sqlplus -S {st.session_state.oracle_user}/{st.session_state.oracle_password}@{tns} @{tmp_sql_mois}",
                timeout=60
            )
            st.write("üì° Lancement sqlplus cumul√©...")
            out_c = run_sqlplus_and_wait(
                f"sqlplus -S {st.session_state.oracle_user}/{st.session_state.oracle_password}@{tns} @{tmp_sql_cum}",
                timeout=60
            )

            # 5.2 Lecture des CSV (sans en-t√™te, UMA;COUNT)
            df_m = read_spool_csv_to_df(spool_mois)
            df_c = read_spool_csv_to_df(spool_cum)
            st.write(f"üìä Spool df_m : {df_m.shape[0]} lignes, df_c : {df_c.shape[0]} lignes")

            # DEBUG console sur les fichiers spool
            print(f"\n====== DEBUG SPOOL POUR SITE {site_label} ======")
            print("df_m (mois) : nb lignes =", len(df_m), ", somme COUNT =", df_m['COUNT'].sum())
            print("df_c (cumul) : nb lignes =", len(df_c), ", somme COUNT =", df_c['COUNT'].sum())
            print("Quelques UMA mois :", df_m.head(10).to_dict(orient='records'))
            print("Quelques UMA cumul :", df_c.head(10).to_dict(orient='records'))
            print("===============================================")

            # 5.3 On ne traite que les TIM / DMU qui concernent CE site
            #     (sinon on m√©lange les bases et on √©crase les valeurs)
            tims_for_site = {
                tim: sites
                for tim, sites in tim_dict.items()
                if site_label in sites
            }

            total_assigned_m = 0.0
            total_assigned_c = 0.0

            st.write("üîπ Calcul RUM par UMA pour ce site...")

            for tim, sites in tims_for_site.items():
                dmus = sites[site_label]
                for dmu, umas in dmus.items():
                    for uma in umas:
                        uma_code = uma["code"]
                        uma_type = uma["type"]

                        base_m = df_m.loc[df_m["UMA"] == uma_code, "COUNT"].sum()
                        base_c = df_c.loc[df_c["UMA"] == uma_code, "COUNT"].sum()

                        # -- DEBUG MATCHING --
                        print("\n===== DEBUG MATCH UMA =====")
                        print(f"SITE={site_label}, TIM=<hidden>, DMU={dmu}")
                        print(f"  UMA libell√© patron = '{uma['libelle']}'")
                        print(f"  UMA_code = '{uma_code}'  (type={uma_type})")
                        print(f"  base_m dans CSV = {base_m}")
                        print(f"  base_c dans CSV = {base_c}")

                        if base_m == 0 and base_c == 0:
                            print("  ‚ö† Aucune correspondance trouv√©e dans CSV")
                        else:
                            print("  ‚úî Correspondance trouv√©e dans CSV")

                        # V√©rifier matching dans df_patron
                        mask_hc = (
                            (df_patron["TIM"] == tim) &
                            (df_patron["SITE"] == site_label) &
                            (df_patron["DMU"] == dmu) &
                            (df_patron["UMA_HC_code"] == uma_code)
                        )
                        mask_hdj = (
                            (df_patron["TIM"] == tim) &
                            (df_patron["SITE"] == site_label) &
                            (df_patron["DMU"] == dmu) &
                            (df_patron["UMA_HDJ_code"] == uma_code)
                        )

                        print(f"  Lignes matching UMA_HC_code = {mask_hc.sum()}")
                        print(f"  Lignes matching UMA_HDJ_code = {mask_hdj.sum()}")

                        if mask_hc.sum() == 0 and mask_hdj.sum() == 0:
                            print("  ‚ùå Aucun matching trouv√© dans df_patron ‚Üí PROBL√àME")
                        else:
                            print("  ‚úî Matching trouv√© dans df_patron")

                        # Si pas de RUM, on arr√™te l√†
                        if base_m == 0 and base_c == 0:
                            continue

                        # R√©partition TIM
                        default_count = uma_to_tim_count.get(uma_code, 1)
                        weight = UMA_WEIGHTS.get(
                            (uma_code, tim),
                            1.0 / default_count if default_count > 0 else 1.0
                        )

                        assigned_m = base_m * weight
                        assigned_c = base_c * weight

                        # Affectation
                        if uma_type == "HC":
                            df_patron.loc[mask_hc, "RUM cod√©s mois"] = assigned_m
                            df_patron.loc[mask_hc, "RUM cod√©s cumul√©s"] = assigned_c
                        else:
                            df_patron.loc[mask_hdj, "RUM relanc√©s mois"] = assigned_m
                            df_patron.loc[mask_hdj, "RUM relanc√©s cumul√©s"] = assigned_c

            # DEBUG r√©sum√© affectation pour le site
            mask_site_patron = (df_patron["SITE"] == site_label)
            print(f"\n====== DEBUG AFFECTATION DF_PATRON POUR SITE {site_label} ======")
            print("Total RUM cod√©s mois (df_patron)   =", df_patron.loc[mask_site_patron, "RUM cod√©s mois"].sum())
            print("Total RUM cod√©s cumul√©s (df_patron)=", df_patron.loc[mask_site_patron, "RUM cod√©s cumul√©s"].sum())
            print("Total RUM relanc√©s mois (df_patron)   =", df_patron.loc[mask_site_patron, "RUM relanc√©s mois"].sum())
            print("Total RUM relanc√©s cumul√©s (df_patron)=", df_patron.loc[mask_site_patron, "RUM relanc√©s cumul√©s"].sum())
            print("Total assigned_m calcul√©           =", total_assigned_m)
            print("Total assigned_c calcul√©           =", total_assigned_c)
            print("==============================================================")

            # Nettoyage fichiers SQL temporaires
            try:
                tmp_sql_mois.unlink()
                tmp_sql_cum.unlink()
            except:
                st.warning(f"‚ö† Impossible de supprimer {tmp_sql_mois} ou {tmp_sql_cum}")

            progress.progress(30 + int((idx_site + 1) * 20))

        # --- 6. Exceptions UMA (150 HTD, 040X CCH, 561C/591C/591J CCH) ---
        st.write("üîπ Application des exceptions UMA...")
        print("\n====== DEBUG AVANT apply_uma_exceptions ======")
        print("Total RUM cod√©s mois global   =", df_patron["RUM cod√©s mois"].sum())
        print("Total RUM relanc√©s mois global=", df_patron["RUM relanc√©s mois"].sum())
        print("==============================================")
        df_patron = apply_uma_exceptions(df_patron)
        print("====== DEBUG APRES apply_uma_exceptions ======")
        print("Total RUM cod√©s mois global   =", df_patron["RUM cod√©s mois"].sum())
        print("Total RUM relanc√©s mois global=", df_patron["RUM relanc√©s mois"].sum())
        print("==============================================\n")

        # --- 8. √âcriture du fichier Excel final ---
        st.write("üîπ √âcriture dans le patron Excel en m√©moire...")
        output = write_copy_with_values_to_patron(df_patron, PATRON_FILL_XLSX)
        st.write("‚úÖ Fichier pr√™t en m√©moire")
        progress.progress(100)

        st.success(f"Traitement termin√© ‚Äî fichier pr√™t au t√©l√©chargement")
        st.download_button(
            "T√©l√©charger le fichier rempli",
            data=output,
            file_name=f"tableau_rum_tim_rempli_{mois:02d}_{annee}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    except Exception as e:
        st.write("‚ùå Exception captur√©e ! :", e)
        safe_show_exception(e)

# ----------------- Page Connexion + session + main (inchang√©s) -----------------
def page_connexion():
    st.title("Connexion Oracle")
    if not st.session_state.logged_in:
        with st.form("connexion"):
            st.subheader("Connexion Oracle")
            user = st.text_input("üë§ Nom d'utilisateur Oracle :", key="conn_user")
            password = st.text_input("üîë Mot de passe :", type="password", key="conn_pwd")
            submitted = st.form_submit_button("üöÄ Se connecter")

        if submitted:
            if not user or not password:
                st.error("Veuillez renseigner vos identifiants Oracle.")
                return
            try:
                st.info("Test de connexion...")
                tns_alias = TNS_MAP["CCH"]
                test_sql_path = SQL_DIR / "test_connexion.sql"
                test_sql_path.write_text("select 1 from dual;\nexit;", encoding="utf-8")
                cmd = f"sqlplus -S {user}/{password}@{tns_alias} @{test_sql_path}"
                out = run_sqlplus_and_wait(cmd, timeout=3)
                if "1" in out:
                    st.session_state.oracle_connected = True
                    st.session_state.logged_in = True
                    st.session_state.oracle_user = user
                    st.session_state.oracle_password = password
                    st.session_state.page = "rum"
                    st.rerun()
                else:
                    st.error("Connexion √©chou√©e. V√©rifiez vos identifiants Oracle.")
            except Exception as e:
                safe_show_exception(e)
            finally:
                try:
                    test_sql_path.unlink()
                except:
                    pass
    else:
        st.success("Connexion active.")
        if st.button("‚û° Aller √† la page RUM"):
            st.session_state.page = "rum"
            st.rerun()

def ensure_session_vars():
    defaults = {
        "logged_in": False,
        "oracle_connected": False,
        "page": "connexion",
        "oracle_user": "",
        "oracle_password": "",
        "last_exception_str": "",
        "show_exception": False
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v

def main():
    st.set_page_config(page_title="RUM TIM", layout="centered")
    ensure_session_vars()
    if st.session_state.page == "connexion":
        page_connexion()
    elif st.session_state.page == "rum":
        if not st.session_state.logged_in:
            st.session_state.page = "connexion"
            st.rerun()
        page_rum()
    else:
        st.session_state.page = "connexion"
        st.rerun()

if __name__ == "__main__":
    main()
